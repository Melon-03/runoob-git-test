# c++

## 智能指针

### 种类及使用场景

![image-20240603102008743](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240603102008743.png)

野指针：指针指向的资源释放了，但是指针没有改成nullptr

指针悬挂：多个指针指向一个资源，某个指针释放了资源，但是其他指针并不知道

踩内存：之前释放的资源重新变成了另外的合法内存 

unique_ptr<class> v_name {make_unique<class>(size)};

shared_ptr<class> v_name{make_shared<class>(size)} ;

class是类名，v_name是指针名，size是class个数，可不填

#### **`std::unique_ptr`**

`std::unique_ptr` 是一种独占所有权的智能指针，确保同一时间内只有一个指针可以拥有所管理的对象。当 `std::unique_ptr` 被销毁时，它所管理的对象也会被销毁。

可以使用release方法转移控制权，但不能拷贝

#### `std::shared_ptr`

`std::shared_ptr` 是一种共享所有权的智能指针，允许多个指针共享同一个对象。当最后一个引用对象的 `std::shared_ptr` 被销毁时，所管理的对象才会被销毁。

原理称为：引用计数，即记录有多少个共享指针指向同一个资源

#### `std::weak_ptr`

`std::weak_ptr` 是一种不拥有对象的智能指针，与 `std::shared_ptr` 结合使用以解决循环引用问题。`std::weak_ptr` 提供对对象的弱引用，不会影响对象的引用计数。

**特点：**

- 不拥有对象

- 不能直接访问对象，需要转换为 `std::shared_ptr` 访问对象

  **示例代码**：

  当wptr引用的sptr还存在时，wptr.lock()返回一个sptr，否则返回空

  ```c++
  cpp复制代码#include <iostream>
  #include <memory>
  
  class MyClass {
  public:
      MyClass() { std::cout << "MyClass constructor\n"; }
      ~MyClass() { std::cout << "MyClass destructor\n"; }
  };
  
  int main() {
      std::shared_ptr<MyClass> sptr(new MyClass());
      std::weak_ptr<MyClass> wptr(sptr); // 弱引用
  
      if (std::shared_ptr<MyClass> locked = wptr.lock()) {
          std::cout << "Managed object is still alive\n";
      } else {
          std::cout << "Managed object has been destroyed\n";
      }
  
      sptr.reset(); // 销毁对象
      if (std::shared_ptr<MyClass> locked = wptr.lock()) {
          std::cout << "Managed object is still alive\n";
      } else {
          std::cout << "Managed object has been destroyed\n";
      }
  
      return 0;
  }
  ```

  

**Core Dump**（核心转储）是程序崩溃时操作系统生成的一种文件，包含程序在崩溃时的内存内容、寄存器状态和执行环境等信息。Core Dump 文件主要用于调试和分析程序崩溃的原因，帮助开发者找出程序中的错误。



**RAII**（Resource Acquisition Is Initialization）是一种资源管理技术，主要用于C++程序设计。RAII思想的核心是将资源的获取与对象的生命周期绑定在一起，通过对象的构造函数获取资源，通过析构函数释放资源。这样可以确保资源在需要时被正确地初始化，并在不需要时被正确地释放，避免资源泄漏和其他相关问题。

#### 底层原理

`std::shared_ptr` 和 `std::weak_ptr` 共享一个控制块（control block），控制块中存储了对象的引用计数和弱引用计数。当创建一个 `shared_ptr` 时，控制块的引用计数增加；当创建一个 `weak_ptr` 时，控制块的弱引用计数增加。

`std::weak_ptr::lock` 的主要作用是检查控制块的引用计数是否大于零（即对象是否仍然存在），如果是，则返回一个新的 `shared_ptr`，否则返回一个空的 `shared_ptr`。

##### 控制块

为了管理引用计数和资源的释放，`std::shared_ptr` 内部包含一个控制块（control block），通常称为引用计数块（reference count block）或管理块（management block）。控制块中包含了引用计数以及指向被管理资源的指针。

控制块的结构大致如下：

```
plaintext复制代码+------------------+
| Reference Count  |  // 引用计数
+------------------+
| Managed Resource |  // 被管理的资源的指针
+------------------+
```

##### 多个 shared_ptr 共享控制块

当多个 `std::shared_ptr` 对象指向同一资源时，它们会共享同一个控制块。这样做可以确保对资源的引用计数被正确地跟踪，避免重复销毁或内存泄漏。

## const的用法

### 1. **指针和常量**

#### A. 指向常量的指针

指向常量的指针不能通过该指针修改所指向的值，但可以改变指针本身指向的地址。

```c++
const int* p = &MAX_SIZE;
```

#### B. 常量指针

常量指针本身的地址不能被修改，但可以通过指针修改所指向的值。

```c++
int value = 10;
int* const p = &value;
*p = 20;  // 可以修改 p 指向的值
// p = &MAX_SIZE;  // 错误，不能修改 p 指向的地址
```

#### C. 指向常量的常量指针

指向常量的常量指针既不能修改所指向的值，也不能改变指针本身指向的地址。

```
const int value = 10;
const int* const p = &value;
// *p = 20;  // 错误，不能修改 p 指向的值
// p = &MAX_SIZE;  // 错误，不能修改 p 指向的地址
```

### 2. **函数参数**

将函数参数声明为`const`，可以防止函数内部修改该参数的值。适用于传递大对象或复杂结构时的效率提升。

```c++
void printValue(const int value) {
    // value = 10;  // 错误，不能修改 value
    std::cout << value << std::endl;
}
```

对于传引用或指针的参数，`const`保证函数内部不能修改传入的对象或指针指向的对象。

### 3. 对象

在类中声明成员函数为`const`，保证该成员函数不能修改对象的任何成员变量。

```c++
class MyClass {
public:
    int getValue() const {
        // value = 10;  // 错误，不能修改成员变量
        return value;
    }
private:
    int value;
};
```

**mutable**：使用`mutable`关键字定义的变量，允许在`const`成员函数中修改。

```c++
class MyClass {
public:
    MyClass(int v) : value(v) {}
    void setCachedValue(int v) const {
        cachedValue = v;  // 可以在const成员函数中修改
    }

private:
    int value;
    mutable int cachedValue;  // mutable成员变量
};
```

**成员函数**：使用`const`修饰成员函数，保证该成员函数不会修改对象的任何成员变量。

**成员变量**：使用`const`修饰成员变量，保证该成员变量在初始化后不可修改。

**对象**：使用`const`修饰对象，保证该对象是不可变的，不能调用任何非`const`成员函数。

**常量成员变量**：类中的常量成员变量需要在构造函数初始化列表中进行初始化。

```c++
class MyClass {
public:
    MyClass(int v) : value(v) {}
private:
    const int value;
};
```

## malloc、free和new、delete的区别

![image-20240602165223124](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602165223124.png)



32位内核空间1G，64位内核空间128T 

32位虚拟内存大小为4G

### malloc是如何分配内存的

malloc会多申请16字节用来存储内存块描述信息

malloc会维护一个内存池，尽量避免系统调用（切换上下文，用户态到内核态的开销）

<128k:优先在内存池上分配，不够的话通过brk系统调用，直接在堆段上分配

》128k：通过mmap（memory map）系统调用在文件映射区分配

### free释放内存

![image-20240602200107851](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602200107851.png)

## 虚函数

![image-20240602165348128](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602165348128.png)

![image-20240602165735549](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602165735549.png)

### 构造函数和析构函数可以是虚函数吗

**构造函数**不能定义为虚函数，因为在对象构造过程中，虚函数表指针vptr尚未初始化，无法正确调用虚函数。

构造函数是在创建对象时自己主动调用的，不可能通过父类的指针或者引用去调用。那使用虚函数也没有实际意义(没有多态），不是对象的动态行为，没有必要成为虚函数。

**析构函数**可以定义为虚函数，以确保通过基类指针删除派生类对象时，正确调用派生类的析构函数，从而防止资源泄漏和未定义行为。

**C++类有继承时，析构函数必须为虚函数。**如果不是虚函数，则使用时可能存在***\*内存泄漏\****的问题。

### 纯虚函数

在C++中，`virtual void draw() const = 0;` 中的 `const = 0` 是指纯虚函数的声明。

- `const`：表示这个成员函数是一个常量成员函数，即在函数体内不能修改对象的成员变量。这个关键字是用于成员函数声明中的，它告诉编译器在调用这个成员函数的过程中不会修改对象的状态。
- `= 0`：表示这个函数是一个纯虚函数。纯虚函数是在基类中声明的虚函数，但它没有具体的实现，相当于接口。任何包含了纯虚函数的类都是抽象类，不能实例化对象。派生类必须实现纯虚函数才能成为可实例化的类。

所以，`virtual void draw() const = 0;` 的意思是声明了一个常量成员函数 `draw()`，它是一个纯虚函数，没有具体的实现，因此类中必须派生出实现它的非抽象类。

## inline关键字

`inline` 关键字在 C++ 中主要用于优化函数调用的性能。通过将函数标记为 `inline`，建议编译器在调用该函数时将其代码嵌入到调用点，而不是执行常规的函数调用（即跳转到函数定义处执行代码，然后返回）。这可以减少函数调用的开销，特别是在频繁调用的小型函数时。

## 动态绑定

动态绑定（Dynamic Binding）是指在程序运行时确定函数调用的具体实现，而不是在编译时就确定。这种机制允许程序在运行时根据实际情况选择合适的函数或方法进行调用，是多态（polymorphism）实现的重要基础。

### 动态绑定的概念

在面向对象编程中，动态绑定通常与虚函数（virtual functions）和接口（interfaces）相关联。动态绑定使得子类可以覆盖（override）父类的方法，并且在运行时可以根据对象的实际类型调用相应的方法实现。这与静态绑定（static binding）或早期绑定（early binding）不同，后者在编译时就确定了函数调用的具体实现。

### 动态绑定的实现机制

动态绑定通常通过虚函数表（vtable）实现。每个类都有一个虚函数表，表中记录了类的虚函数指针。当一个对象调用虚函数时，程序会查找对象对应的虚函数表，找到实际要调用的函数地址。

#### 虚函数表（vtable）

- **定义**：虚函数表是一个指针数组，数组中的每个指针指向类的虚函数实现。
- **对象的指针**：每个对象有一个指向它所属类的虚函数表的指针（通常称为虚表指针或vptr）。

### 动态绑定的示例

以下是一个C++中的示例，展示了如何通过虚函数实现动态绑定：

```c++
#include <iostream>

class Base {
public:
    virtual void show() {
        std::cout << "Base class show function called" << std::endl;
    }
};

class Derived : public Base {
public:
    void show() override {
        std::cout << "Derived class show function called" << std::endl;
    }
};

int main() {
    Base* basePtr;
    Derived derivedObj;

    basePtr = &derivedObj;

    // 动态绑定：调用基类指针指向的实际对象的函数
    basePtr->show();  // Output: Derived class show function called

    return 0;
}
```

在这个例子中：

- `Base`类有一个虚函数`show`。
- `Derived`类继承自`Base`并覆盖了`show`函数。
- 在`main`函数中，基类指针`basePtr`指向派生类对象`derivedObj`。
- 调用`basePtr->show()`时，程序在运行时决定调用`Derived`类的`show`方法。

### 动态绑定的优点

1. **多态性**：动态绑定是实现多态的基础，使得相同的函数调用可以根据对象的实际类型调用不同的实现。
2. **可扩展性**：增加新的子类时，不需要修改现有代码，只需要定义新的子类并实现相应的虚函数。
3. **灵活性**：使得程序更加灵活，可以处理更多类型的对象和场景。

### 动态绑定的缺点

1. **性能开销**：由于动态绑定在运行时决定函数调用，有一定的性能开销（查找虚函数表、间接调用）。
2. **复杂性**：程序设计和调试变得更加复杂，需要理解虚函数表和多态机制。

### 总结

动态绑定是面向对象编程中实现多态性的关键机制，使得程序可以在运行时根据对象的实际类型调用相应的方法实现。它通过虚函数表等机制实现，提供了灵活性和可扩展性，但也带来了一定的性能开销和复杂性。理解动态绑定的工作原理对于编写和优化面向对象程序非常重要。

## STL

### C++中的`std::list`

C++标准库提供了`std::list`，这是一个双向链表实现。`std::list`在`<list>`头文件中定义。

#### 特点

- **双向链表**：每个元素都有指向前一个和后一个元素的指针。
- **高效插入和删除**：在任何位置插入和删除元素都非常高效。
- **顺序访问**：不支持随机访问（不像`std::vector`），只能顺序访问元素。

#### 使用示例

```c++
#include <iostream>
#include <list>

int main() {
    std::list<int> myList;

    // 插入元素
    myList.push_back(10);
    myList.push_back(20);
    myList.push_back(30);

    // 遍历列表
    for (int value : myList) {
        std::cout << value << " ";
    }
    std::cout << std::endl;

    // 删除元素
    myList.pop_front(); // 删除第一个元素

    // 遍历列表
    for (int value : myList) {
        std::cout << value << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

#### 主要操作

- **插入**：`push_back`、`push_front`、`insert`
- **删除**：`pop_back`、`pop_front`、`erase`
- **访问**：`front`、`back`
- **遍历**：使用迭代器或范围for循环

## 拷贝构造函数

![image-20240602165956247](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602165956247.png)

### 浅拷贝（Shallow Copy）：

- 浅拷贝只是复制了对象本身以及其内部的数据，但对于内部的引用类型成员（指针、引用等），只是拷贝了引用的地址，而不是引用指向的对象。因此，原对象和拷贝后的对象会共享同一个内部对象。

### 深拷贝（Deep Copy）：

- 深拷贝不仅复制了对象本身，还递归地复制了对象内部所有的引用类型成员指向的对象，确保原对象和拷贝后的对象完全独立，互不影响。

## 设计模式

### 装饰器

![image-20240606092208436](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240606092208436.png)

装饰器是一种结构型设计模式，它允许在不改变对象自身行为的情况下，动态地添加新功能。在C++中，装饰器模式通常通过组合和继承来实现。

#### 装饰器模式的组成部分：

1. **组件（Component）**：定义了一个对象接口，可以给这些对象动态地添加新的职责。在C++中通常是一个抽象基类或接口。
2. **具体组件（Concrete Component）**：实现了组件接口，是被装饰的对象。
3. **装饰器（Decorator）**：持有一个指向组件对象的指针，并实现了组件的接口。通常是一个抽象基类，它的子类用于具体的装饰功能。
4. **具体装饰器（Concrete Decorator）**：扩展了装饰器，并且向组件添加新的职责。可以有多个具体装饰器，它们可以按照自己的需要进行组合。

#### 示例：

考虑一个简单的文本修饰器，它可以在文本前后添加装饰（如加粗、斜体等）。我们首先定义一个文本组件接口：

```c++
class TextComponent {
public:
    virtual void draw() const = 0;
    virtual ~TextComponent() = default;
};
```

然后实现具体的文本组件：

```c++
class SimpleText : public TextComponent {
public:
    void draw() const override {
        std::cout << "Hello, world!" << std::endl;
    }
};
```

接下来定义装饰器接口：

```c++
class TextDecorator : public TextComponent {
protected:
    TextComponent* component;
public:
    TextDecorator(TextComponent* component) : component(component) {}
    void draw() const override {
        if (component) {
            component->draw();
        }
    }
    ~TextDecorator() override {
        delete component;
    }
};
```

然后实现具体的装饰器：

```c++
class BoldText : public TextDecorator {
public:
    BoldText(TextComponent* component) : TextDecorator(component) {}
    void draw() const override {
        std::cout << "<b>";
        TextDecorator::draw();
        std::cout << "</b>";
    }
};
```

使用示例：

```c++
int main() {
    TextComponent* text = new SimpleText();
    TextComponent* boldText = new BoldText(text);

    boldText->draw(); // 输出： <b>Hello, world!</b>

    delete boldText;
    return 0;
}
```

在这个示例中，`SimpleText`是一个具体的文本组件，`BoldText`是一个具体的装饰器，它扩展了文本组件并向其添加了加粗的功能。通过组合和继承，装饰器模式使得代码的可扩展性和灵活性大大增强。

## 面对对象的三大特征及特性

![image-20240602190038070](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602190038070.png)

![image-20240602190515854](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602190515854.png)

### 封装

### 继承

权限继承：

例如：class b: protected A{ };

指子类b继承到基类A的最高权限是protected，即A中的public到了b中会变成protected.

![image-20240602190155358](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602190155358.png)

friend class A使得A可以访问B的private

### 多态

#### 函数重载

函数重载的规则

1. **参数数量不同**：可以通过定义具有不同数量参数的函数来实现重载。
2. **参数类型不同**：可以通过定义具有不同类型参数的函数来实现重载。
3. **参数顺序不同**：可以通过定义具有相同数量但顺序不同的参数的函数来实现重载。

注意：函数的返回类型不参与函数重载的判定。

## C++中的内存分配

是一个重要的概念，涉及程序运行时如何管理和分配内存资源。内存分配主要分为两类：静态内存分配和动态内存分配。

### 静态内存分配

静态内存分配在编译时完成，内存的大小和位置在编译时就已经确定。这种分配方式通常用于全局变量、局部静态变量和常量。

- **全局变量**：在程序开始运行时分配内存，并在程序结束时释放。
- **局部静态变量**：在第一次调用函数时分配内存，并在程序结束时释放。
- **常量**：如`const`关键字声明的常量。

### 动态内存分配

动态内存分配是在程序运行时按需分配和释放内存的。这种分配方式更灵活，但需要程序员手动管理内存的分配和释放。C++中主要通过`new`和`delete`操作符来实现动态内存分配。

## union联合体

在C++中，`union`（联合体）是一种特殊的数据结构，允许在同一个内存位置存储不同类型的变量。联合体中所有成员共用同一块内存，这意味着在任一时刻，联合体只能保存一个成员的值。联合体的主要用途是在需要节省内存的场合，因为它提供了一种在同一内存空间中存储不同数据类型的方法。

### 声明和使用`union`

#### 声明联合体

联合体的声明方式类似于结构体，只不过使用`union`关键字而不是`struct`。

```c++
union MyUnion {
    int i;
    float f;
    char c;
};
```

在这个例子中，`MyUnion`可以存储一个整数（`i`）、一个浮点数（`f`）或一个字符（`c`），但只能同时存储其中一个。

### 联合体的大小和对齐

联合体的大小等于其最大成员的大小，以保证能够存储其中最大的成员。联合体的对齐方式与结构体类似，也取决于其成员的最大对齐要求。

```c++
union Data {
    int i;
    double d;
    char c;
};

cout << "Size of union Data: " << sizeof(Data) << endl;
```

在这个例子中，`union Data`的大小将等于其最大成员（`double d`）的大小。

### 联合体的限制

由于联合体的特殊性质，在使用联合体时有一些限制：

1. **只能保存一个成员的值**：联合体的所有成员共用同一块内存，因此在任一时刻只能保存一个成员的值。
2. **不支持非平凡的构造函数和析构函数**：联合体的成员不能是具有非平凡构造函数或析构函数的类型。这意味着你不能在联合体中包含包含类对象，除非这些类具有平凡的构造函数和析构函数。
3. **未定义行为**：在访问联合体的成员时，如果访问的成员不是最后一个赋值的成员，结果是未定义的。

## 类型安全问题

在C++中，类型安全（type safety）是指程序在运行时不会出现类型不一致的错误。C++在设计中支持强类型系统，但仍存在一些潜在的类型安全问题，特别是在使用一些低级特性时。以下是C++中可能导致类型安全问题的几个主要方面及其解决方法：

1. **联合体（Union）**：

   - 联合体的成员共享同一块内存，所以在访问一个未被正确初始化的成员时会导致未定义行为。

   ```c++
   union MyUnion {
       int i;
       float f;
   };
   
   MyUnion u;
   u.i = 42;
   std::cout << u.f; // 可能导致未定义行为，因为u.f未初始化
   ```

2. **类型转换（Type Casting）**：

   - 使用C风格的类型转换或`reinterpret_cast`可能会破坏类型安全，因为它们不执行类型检查。

   ```c++
   int i = 10;
   float* f = (float*)&i; // C风格的类型转换，不安全
   *f = 3.14f; // 未定义行为
   ```

3. **指针和引用**：

   - 通过指针或引用访问对象的类型不匹配也会导致未定义行为。

   ```
   int i = 42;
   void* p = &i; // void* 指针没有类型信息
   float* f = static_cast<float*>(p); // 错误的类型转换
   *f = 3.14f; // 未定义行为
   ```

4. **内存管理**：

   - 手动管理内存时，错误地分配和释放内存可能会导致类型安全问题。

   ```
   cpp复制代码int* p = new int[10];
   delete p; // 应该使用 delete[]
   ```

5. **变量的未初始化**：

   - 使用未初始化的变量会导致未定义行为。

   ```
   cpp复制代码int x;
   std::cout << x; // 未定义行为
   ```

### 解决方法

1. **使用安全的类型转换**：

   - 使用C++提供的类型转换操作符，如`static_cast`、`dynamic_cast`、`const_cast`和`reinterpret_cast`，并确保类型转换是安全和合理的。

   ```
   int i = 42;
   void* p = &i;
   int* ip = static_cast<int*>(p); // 安全的类型转换
   ```

2. **初始化变量**：

   - 在声明变量时确保它们被初始化。

   ```
   cpp
   复制代码
   int x = 0; // 初始化变量
   ```

3. **避免使用联合体**：

   - 尽量避免使用联合体。如果必须使用，确保使用前检查当前有效的成员，并考虑使用`std::variant`来替代联合体，它在C++17中引入并提供类型安全的联合体功能。

   ```
   cpp复制代码#include <variant>
   
   std::variant<int, float> v;
   v = 42;
   std::cout << std::get<int>(v); // 类型安全的访问
   ```

4. **使用类型安全的容器和函数**：

   - 使用标准库提供的容器和函数，它们通常是类型安全的。

   ```
   std::vector<int> vec = {1, 2, 3};
   vec.push_back(4); // 类型安全的操作
   ```

### 小结

类型安全是C++编程中的一个重要概念，确保程序在运行时不会出现类型不一致的错误。通过使用安全的类型转换、智能指针、类型安全的容器和函数，以及避免使用容易导致类型不安全的特性（如联合体和C风格的类型转换），可以提高程序的类型安全性，减少未定义行为和潜在的错误。

## 模板函数是作用在什么时候

答：编译阶段。

模板函数的编译过程分为几个阶段，主要包括模板定义、实例化和代码生成。这些阶段可以归纳为以下几个步骤：

### 1. 模板定义阶段

在程序中定义模板函数时，并不会立即生成具体的函数代码。这一阶段只是向编译器声明了一种泛型的函数模式。编译器记录下模板的定义，并等待实际调用时根据具体类型进行实例化。

```
cpp复制代码template <typename T>
T add(T a, T b) {
    return a + b;
}
```

在这个阶段，编译器只知道存在一个模板函数 `add`，但并不会生成具体的代码。

### 2. 模板实例化阶段

模板实例化发生在编译期（compile-time）。当模板函数被调用时，编译器会根据传入的具体类型生成对应的实例化代码。实例化过程将模板参数替换为具体的类型，生成特定类型的函数定义。

```
cpp复制代码int main() {
    int result = add(3, 4);          // 实例化为 int add(int, int)
    double dresult = add(3.0, 4.5);  // 实例化为 double add(double, double)
}
```

在这里，编译器看到 `add(3, 4)` 和 `add(3.0, 4.5)` 的调用时，会实例化两个函数：

- 一个是 `int add(int, int)`
- 另一个是 `double add(double, double)`

### 3. 编译期的类型检查和代码生成

在模板实例化之后，编译器会对生成的具体函数进行类型检查和代码生成。如果模板函数的实现中有任何类型不匹配或语法错误，这些错误会在编译期被捕获。例如，如果模板函数试图使用特定类型不支持的操作，编译器会报错。

```
cpp复制代码template <typename T>
T multiply(T a, T b) {
    return a * b;
}

int main() {
    int result = multiply(3, 4);          // 正常实例化
    // std::string sresult = multiply(std::string("a"), std::string("b")); // 编译错误，std::string 没有乘法操作
}
```

### 4. 链接阶段

模板函数在编译期实例化生成后，和普通函数一样，进入链接阶段。在这个阶段，所有的实例化函数会被链接在一起。如果模板函数定义在头文件中（通常是这种情况），而头文件被多个翻译单元（源文件）包含，链接器会处理这些实例化函数的重定义问题。

### 总结

模板函数的主要作用阶段是编译期。具体步骤如下：

1. **模板定义阶段**：模板函数定义被编译器记录下来，但不生成具体代码。
2. **模板实例化阶段**：当模板函数被调用时，编译器根据调用时提供的具体类型生成具体函数代码。
3. **编译期类型检查和代码生成**：编译器对实例化的模板函数进行类型检查，并生成对应的机器代码。如果有错误，会在此阶段报告。
4. **链接阶段**：将所有实例化函数链接在一起，处理可能的重定义问题。

这种编译期处理机制使得模板函数具有极大的灵活性和高效性，同时也要求开发者对类型的兼容性和模板使用场景有较好的理解。

## 引用类型

引用类型是类、接口或数组的实例，用于表示复杂的数据结构。它们在堆上分配内存，并通过引用进行操作。引用类型可以包含基本类型的数据以及其他引用类型。C++中的`std::string`和Java中的`String`都是引用类型。

在C++和Java中，引用类型是指通过引用来访问对象的数据类型。引用类型与基本数据类型不同，基本数据类型直接包含实际的值，而引用类型包含对数据的引用（或地址）。引用类型包括类、接口、数组等。

- **C++**：所有类类型（如`std::string`、自定义类等）和数组都是引用类型。

## 链接过程

在C++编译过程中，链接（linking）是一个至关重要的阶段。链接的主要任务是将编译生成的目标文件（object files）和库文件（libraries）结合在一起，生成可执行文件（executable）。链接过程可以分为两个主要阶段：静态链接（static linking）和动态链接（dynamic linking）。

### 链接的基本概念

#### 目标文件

目标文件是编译器将源代码（如 .cpp 文件）翻译成的二进制文件（通常是 .o 或 .obj 文件）。每个目标文件包含了从源文件翻译过来的机器码、符号表（symbol table）、调试信息等。

#### 符号表

符号表记录了程序中的所有符号（如变量、函数）的名称和地址信息。符号可以分为两类：

- **定义符号**：在当前目标文件中定义的符号。
- **引用符号**：当前目标文件中引用但未定义的符号，这些符号需要从其他目标文件或库中解析。

### 静态链接（Static Linking）

静态链接在编译时将所有需要的目标文件和静态库文件结合成一个单独的可执行文件。静态链接的结果是一个包含所有依赖代码的可执行文件。

#### 静态链接的步骤

1. **符号解析**：链接器遍历所有目标文件和库文件，解析每个符号的定义和引用。
2. **地址绑定**：将每个符号的引用绑定到其定义的地址上。
3. **段合并**：将各个目标文件的段（如代码段、数据段）合并成一个单独的段。
4. **生成可执行文件**：将所有内容写入最终的可执行文件中。

#### 优点和缺点

**优点**：

- 可执行文件独立性强，不依赖于外部库文件的存在。
- 运行时不需要额外的加载步骤，启动速度快。

**缺点**：

- 可执行文件体积大，因为包含了所有依赖代码。
- 升级和维护困难，需要重新编译和链接整个应用程序。

### 动态链接（Dynamic Linking）

动态链接在运行时将程序与动态库（如 .so 文件或 .dll 文件）结合在一起。动态库在程序启动或执行过程中按需加载。

#### 动态链接的步骤

1. **符号解析**：在编译时生成包含动态库引用的目标文件，链接器只记录符号的引用而不实际解析。
2. **生成可执行文件**：生成的可执行文件包含对动态库的引用信息。
3. **运行时链接**：当程序运行时，动态链接器（如 ld.so）负责加载所需的动态库并解析符号。

#### 优点和缺点

**优点**：

- 可执行文件体积小，因为库文件在运行时单独加载。
- 共享库可以被多个程序共享，减少内存使用和磁盘空间。
- 便于库的升级和维护，无需重新编译应用程序，只需替换动态库。

**缺点**：

- 运行时需要加载动态库，可能增加启动时间。
- 依赖动态库的存在，若库文件缺失或版本不匹配，程序可能无法运行。

### 链接器的工作流程

1. **符号收集**：收集所有目标文件中的符号表信息，识别所有定义和引用的符号。
2. **符号解析**：将每个引用符号解析到对应的定义符号，确保所有引用符号都能找到对应的定义。
3. **地址分配**：为每个符号分配内存地址，解决不同目标文件和库文件之间的地址冲突。
4. **段合并和重定位**：将所有目标文件的相同类型段（如代码段、数据段）合并，并进行地址重定位。
5. **生成可执行文件**：将所有处理后的段和符号信息写入最终的可执行文件。

### 链接错误

在链接过程中，常见的错误包括：

- **未定义引用错误（undefined reference）**：目标文件中引用了未定义的符号。
- **重复定义错误（multiple definition）**：同一个符号在多个目标文件中被重复定义。
- **库文件缺失错误**：程序依赖的库文件未能找到。

### 总结

链接是C++编译过程中的一个关键阶段，将多个目标文件和库文件组合成一个可执行文件。链接过程可以是静态链接或动态链接，各有优缺点。理解链接过程和可能出现的错误对于解决编译问题和优化程序性能至关重要。

## static_cast和dynamic_cast有什么区别

### 总结

| 特性         | `static_cast`                              | `dynamic_cast`                                  |
| ------------ | ------------------------------------------ | ----------------------------------------------- |
| 类型检查     | 编译时                                     | 运行时                                          |
| 用途         | 一般类型转换、基础类型转换、非多态类型转换 | 多态类型转换（基类和派生类之间）                |
| 安全性       | 由程序员保证                               | 由运行时检查保证                                |
| 转换失败行为 | 无                                         | 指针类型转换返回`nullptr`，引用类型转换抛出异常 |
| 开销         | 无运行时开销                               | 有运行时开销                                    |

## 内联函数和宏有什么区别

| 特性     | 宏                       | 内联函数               |
| -------- | ------------------------ | ---------------------- |
| 定义方式 | `#define`                | `inline` 关键字        |
| 类型检查 | 否                       | 是                     |
| 替换方式 | 预处理阶段的文本替换     | 编译阶段的内联展开     |
| 调试     | 难以调试                 | 容易调试               |
| 安全性   | 易出错，可能有副作用     | 安全，避免副作用       |
| 参数处理 | 直接替换，可能有重复计算 | 按值传递，避免重复计算 |

## 编译阶段和预处理阶段的对比

| 特性     | 预处理阶段                         | 编译阶段                           |
| -------- | ---------------------------------- | ---------------------------------- |
| 主要任务 | 宏替换、文件包含、条件编译、去注释 | 语法分析、语义分析、代码生成和优化 |
| 操作方式 | 文本替换                           | 高级代码转换为低级代码             |
| 工具     | 预处理器                           | 编译器                             |
| 结果     | 预处理后的纯源代码                 | 目标文件（机器码）                 |
| 时间点   | 编译前                             | 编译中                             |

## 编译阶段的步骤

编译阶段是将预处理后的源代码转换为目标代码（机器码）的过程。这个阶段主要由编译器完成，负责将高层次的编程语言翻译成机器可以理解的低层次语言。

### 主要任务

1. **语法分析**：
   - 编译器检查代码的语法是否正确，确保符合语言的语法规则。
2. **语义分析**：
   - 编译器检查代码的语义，确保每个操作符的使用是合适的，并进行类型检查。
3. **中间代码生成**：
   - 编译器将源代码转换为一种中间表示形式（中间代码），这使得优化和生成目标代码更加容易。
4. **代码优化**：
   - 编译器对中间代码进行优化，以提高运行效率和减少内存使用。
   - 例如，消除死代码，循环优化等。
5. **目标代码生成**：
   - 编译器将中间代码转换为目标机器代码，生成目标文件（通常是`.obj`或`.o`文件）。

## 面向对象程序设计的五大原则SOLID原则

**单一职责原则（Single Responsibility Principle, SRP）**

**开闭原则（Open/Closed Principle, OCP）**

**里氏替换原则（Liskov Substitution Principle, LSP）**

**接口隔离原则（Interface Segregation Principle, ISP）**

**依赖倒置原则（Dependency Inversion Principle, DIP）**



### 1. 单一职责原则（SRP）

一个类应该只有一个引起它变化的原因，即一个类应该只有一个职责。该原则的目的是降低类的复杂度，提高类的可维护性和可重用性。

#### 示例

```
cpp复制代码class Report {
public:
    void generateReport() {
        // 生成报告的代码
    }

    void printReport() {
        // 打印报告的代码
    }
};
```

这个类违反了单一职责原则，因为它同时负责生成和打印报告。可以将其分为两个类：

```
cpp复制代码class ReportGenerator {
public:
    void generateReport() {
        // 生成报告的代码
    }
};

class ReportPrinter {
public:
    void printReport() {
        // 打印报告的代码
    }
};
```

### 2. 开闭原则（OCP）

软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。也就是说，应该通过扩展已有代码的方式来实现新的功能，而不是通过修改已有代码。

#### 示例

```cpp
class Rectangle {
public:
    virtual double area() const {
        return width * height;
    }
    
private:
    double width;
    double height;
};

class Circle {
public:
    virtual double area() const {
        return radius * radius * 3.14159;
    }
    
private:
    double radius;
};
```

为了实现开闭原则，可以通过引入一个接口（抽象类）来进行扩展：

```cpp
class Shape {
public:
    virtual double area() const = 0;
};

class Rectangle : public Shape {
public:
    double area() const override {
        return width * height;
    }

private:
    double width;
    double height;
};

class Circle : public Shape {
public:
    double area() const override {
        return radius * radius * 3.14159;
    }

private:
    double radius;
};
```

### 3. 里氏替换原则（LSP）

子类对象应该可以替换父类对象，并且不会导致程序的行为发生变化。也就是说，使用基类的地方应该能够透明地使用其子类。

#### 示例

```cpp
class Bird {
public:
    virtual void fly() {
        // 飞行的代码
    }
};

class Sparrow : public Bird {
public:
    void fly() override {
        // 麻雀飞行的代码
    }
};

class Ostrich : public Bird {
public:
    void fly() override {
        // 鸵鸟不能飞，这里违反了里氏替换原则
    }
};
```

在这种情况下，`Ostrich`不能飞，因此它不应该继承`Bird`类。可以通过引入新的抽象层来解决这个问题：

```cpp
class Bird {
public:
    virtual void move() = 0;
};

class FlyingBird : public Bird {
public:
    void move() override {
        fly();
    }

    virtual void fly() = 0;
};

class NonFlyingBird : public Bird {
public:
    void move() override {
        walk();
    }

    virtual void walk() = 0;
};

class Sparrow : public FlyingBird {
public:
    void fly() override {
        // 麻雀飞行的代码
    }
};

class Ostrich : public NonFlyingBird {
public:
    void walk() override {
        // 鸵鸟行走的代码
    }
};
```

### 4. 接口隔离原则（ISP）

客户端不应该被迫依赖于它不使用的方法。也就是说，接口应该小而专，避免臃肿。

#### 示例

```cpp
class IWorker {
public:
    virtual void work() = 0;
    virtual void eat() = 0;
};

class Worker : public IWorker {
public:
    void work() override {
        // 工作的代码
    }

    void eat() override {
        // 吃饭的代码
    }
};

class Robot : public IWorker {
public:
    void work() override {
        // 机器人的工作代码
    }

    void eat() override {
        // 机器人不需要吃饭，但必须实现这个方法，违反了ISP
    }
};
```

可以通过分离接口来解决这个问题：

```cpp
class IWorkable {
public:
    virtual void work() = 0;
};

class IFeedable {
public:
    virtual void eat() = 0;
};

class Worker : public IWorkable, public IFeedable {
public:
    void work() override {
        // 工作的代码
    }

    void eat() override {
        // 吃饭的代码
    }
};

class Robot : public IWorkable {
public:
    void work() override {
        // 机器人的工作代码
    }
};
```

### 5. 依赖倒置原则（DIP）

高层模块不应该依赖于低层模块，两者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。该原则的目的是降低模块之间的耦合性。

#### 示例

```cpp
class LightBulb {
public:
    void turnOn() {
        // 开灯的代码
    }

    void turnOff() {
        // 关灯的代码
    }
};

class Switch {
public:
    void operate(bool on) {
        if (on) {
            lightBulb.turnOn();
        } else {
            lightBulb.turnOff();
        }
    }

private:
    LightBulb lightBulb;
};
```

在这个例子中，`Switch`类依赖于具体的`LightBulb`类，违反了DIP。可以通过引入抽象层来解决这个问题：

```cpp
class ISwitchable {
public:
    virtual void turnOn() = 0;
    virtual void turnOff() = 0;
};

class LightBulb : public ISwitchable {
public:
    void turnOn() override {
        // 开灯的代码
    }

    void turnOff() override {
        // 关灯的代码
    }
};

class Switch {
public:
    Switch(ISwitchable& switchableDevice) : device(switchableDevice) {}

    void operate(bool on) {
        if (on) {
            device.turnOn();
        } else {
            device.turnOff();
        }
    }

private:
    ISwitchable& device;
};
```

在这个例子中，`Switch`类依赖于`ISwitchable`接口，而不是具体的`LightBulb`类，从而遵循了依赖倒置原则。

## 构造函数有哪几种

**1.默认构造函数（Default Constructor）**：

- 无参数的构造函数。
- 如果类中没有定义任何构造函数，编译器会提供一个默认构造函数。

```cpp
class Example {
public:
    Example() {
        // 默认构造函数
    }
};
```

**2.参数化构造函数（Parameterized Constructor）**：

- 接受一个或多个参数，用于对象的初始化。

```cpp
class Example {
public:
    Example(int a, int b) {
        // 参数化构造函数
    }
};
```

**3.拷贝构造函数（Copy Constructor）**：

- 用于通过另一个对象来初始化新对象。
- 通常形式为 `ClassName(const ClassName &other)`。

```cpp
class Example {
public:
    Example(const Example &other) {
        // 拷贝构造函数
    }
};
```

**4.移动构造函数（Move Constructor）**（在 C++ 中）：

- 用于通过移动资源来初始化新对象，通常形式为 `ClassName(ClassName &&other)`。
- 常用于优化性能，避免不必要的拷贝。

```cpp
class Example {
public:
    Example(Example &&other) noexcept {
        // 移动构造函数
    }
};
```

**5.委托构造函数（Delegating Constructor）**（在 C++11 及更高版本中）：

- 一个构造函数调用另一个构造函数来实现初始化。

```cpp
class Example {
public:
    Example() : Example(0, 0) {
        // 委托构造函数
    }
    
    Example(int a, int b) {
        // 参数化构造函数
    }
};
```

**构造函数列表初始化（Constructor Initialization List）**（在 C++ 中）：

- 用于在构造函数体之前初始化成员变量，提高效率。

```cpp
class Example {
    int a;
    int b;
public:
    Example(int x, int y) : a(x), b(y) {
        // 构造函数列表初始化
    }
};
```

## 左值和右值

### 左值（lvalue）

**定义**：左值是指在程序运行期间有确定的存储地址（内存位置）的对象。左值可以出现在赋值操作符的左边，也可以出现在右边。

**特点**：

1. **可寻址**：左值代表一个可寻址的存储位置，表示对象的持久状态。
2. **生命周期长**：左值通常具有较长的生命周期，可以在多个操作中被引用。
3. **引用类型**：可以通过引用来绑定左值。

**示例**：

```cpp
int x = 10;   // x 是一个左值
x = 20;       // 左值 x 出现在赋值操作符的左边
int& ref = x; // 可以通过引用绑定左值
```

### 右值（rvalue）

**定义**：右值是指在程序运行期间没有固定存储地址的临时值。右值通常是表达式的结果，并且生命周期较短。

**特点**：

1. **不可寻址**：右值表示临时值或字面常量，通常不可直接寻址。
2. **生命周期短**：右值的生命周期通常仅限于它所在的表达式。
3. **不可通过引用绑定**：传统的右值不能通过左值引用绑定，但可以通过右值引用绑定（C++11 引入）。

**示例**：

```cpp
int y = 10;
int z = y + 5; // y + 5 是一个右值
z = 15;        // 15 是一个右值
```

### 右值引用（rvalue references）

**定义**：右值引用是一种能够绑定到右值的引用类型，它使用 `&&` 语法。右值引用的引入主要是为了实现移动语义和完美转发，以提高程序性能。

**特点**：

1. **右值绑定**：右值引用只能绑定到右值。
2. **移动语义**：通过右值引用，可以实现对象资源的移动，而不是复制，从而提高效率。
3. **完美转发**：右值引用可以用于模板中，实现参数的完美转发。

**示例**：

```cpp
int&& rref = 10;   // rref 是一个右值引用，绑定到右值 10

void foo(int&& arg) {
    int local = std::move(arg); // 通过 std::move 实现资源移动
}

foo(20); // 20 是右值，传递给右值引用参数 arg
```

### 左值和右值的用途

- **左值**：
  - 适用于需要多次使用、修改的对象。
  - 可以通过指针和引用操作。
- **右值**：
  - 适用于临时计算结果、字面常量等。
  - 在优化和资源管理中，通过右值引用实现高效的资源转移。

### 左值和右值的进一步分类（C++11）

C++11 引入了更细致的分类，包括纯右值（prvalue）和将亡值（xvalue）：

- **纯右值（prvalue）**：不具有持久存储的临时值。例如：字面常量、临时对象。
- **将亡值（xvalue）**：表示即将被销毁的值，例如：通过 `std::move` 转移后的对象。

### 小结

左值和右值的区分在C++中非常重要，特别是对于资源管理和性能优化。通过理解它们的差异和用途，可以编写更高效和安全的代码。

## noexcept关键字

`noexcept`是C++11引入的一个关键字，用于指示函数不会抛出异常。它在函数声明、定义和表达式中都可以使用，以增强程序的异常安全性和性能。以下是对`noexcept`的详细解释。

**1. `noexcept`的基本用法**

**声明函数不抛出异常**：

在函数声明和定义中使用`noexcept`可以明确表示该函数不会抛出异常。这有助于编译器进行优化，并提高代码的可读性和维护性。

**语法**：

```
cpp
复制代码
void myFunction() noexcept;
```

**示例**：

```
cpp复制代码void safeFunction() noexcept {
    // 该函数不会抛出异常
}

void riskyFunction() {
    // 该函数可能会抛出异常
}
```

**2. 条件`noexcept`**

可以使用条件`noexcept`来根据某些条件判断函数是否会抛出异常。这在模板编程中特别有用，因为函数是否抛出异常可能取决于模板参数。

**语法**：

```
cpp
复制代码
void myFunction() noexcept(condition);
```

**示例**：

```
cpp复制代码template <typename T>
void conditionalFunction(T&& t) noexcept(noexcept(process(std::forward<T>(t)))) {
    process(std::forward<T>(t));
}
```

在这个示例中，`conditionalFunction`的`noexcept`条件依赖于`process`函数是否是`noexcept`。

**3. `noexcept`运算符**

`noexcept`运算符可以用于在编译时检查表达式是否为`noexcept`，返回一个布尔值。这在编写泛型代码时非常有用。

**语法**：

```
cpp
复制代码
bool isNoexcept = noexcept(expression);
```

**示例**：

```
cpp复制代码void mayThrow();
void noThrow() noexcept;

int main() {
    bool b1 = noexcept(mayThrow()); // false
    bool b2 = noexcept(noThrow());  // true
}
```

**4. `noexcept`的优点**

1. **性能优化**：编译器可以根据`noexcept`进行更好的优化，例如减少不必要的异常处理代码。
2. **提高安全性**：明确标识不会抛出异常的函数，可以帮助程序员更好地理解和维护代码。
3. **提高代码质量**：通过条件`noexcept`和`noexcept`运算符，可以编写更加健壮和灵活的模板代码。

**5. 标准库中的`noexcept`**

标准库中的许多函数和容器操作都标记为`noexcept`，以确保其高效和安全。例如，C++11及更高版本中的移动构造函数和移动赋值操作通常被标记为`noexcept`。

**示例**：

```
cpp复制代码#include <vector>
#include <iostream>

int main() {
    std::vector<int> vec1{1, 2, 3};
    std::vector<int> vec2{4, 5, 6};

    std::cout << std::boolalpha;
    std::cout << noexcept(vec1 = std::move(vec2)) << std::endl; // true
}
```

在这个示例中，移动赋值操作是`noexcept`的，因为标准库实现保证了它不会抛出异常。

**小结**

`noexcept`关键字是C++11引入的一项重要特性，通过明确标识函数和表达式不会抛出异常，帮助编译器进行优化，增强程序的性能和异常安全性。使用`noexcept`可以提高代码的可读性、维护性和整体质量。

## struct中的内存对齐

在C++中，结构体（`struct`）的内存对齐（memory alignment）是指将结构体的成员变量存储在内存中的特定位置，以满足硬件和性能要求。内存对齐可以减少CPU访问内存时的开销，提高程序的执行效率。下面是关于结构体内存对齐的详细解释。

**内存对齐的基本概念**

1. **对齐要求**：每个数据类型都有其对齐要求，通常是其大小的整数倍。例如，`int`通常需要4字节对齐，`double`通常需要8字节对齐。
2. **内存填充**：为了满足对齐要求，编译器可能在结构体成员之间插入一些额外的字节（填充字节），使得每个成员都按照其对齐要求对齐。
3. **结构体对齐**：结构体的对齐方式通常是其最大成员的对齐方式。

**示例**

考虑以下结构体：

```
cpp复制代码struct Example {
    char a;   // 1字节
    int b;    // 4字节
    char c;   // 1字节
};
```

如果没有对齐，`Example`的大小将是 `1 + 4 + 1 = 6` 字节。但由于对齐要求，实际内存布局可能如下：

```
scss复制代码Offset  Member
0       a (1 byte)
1       (padding, 3 bytes)
4       b (4 bytes)
8       c (1 byte)
9       (padding, 3 bytes)
```

在这个例子中：

- `a` 在偏移量0处，后面有3个字节的填充，使得 `b` 在4字节边界对齐。
- `b` 在偏移量4处，满足4字节对齐要求。
- `c` 在偏移量8处，后面有3个字节的填充，使得结构体的总大小是12字节（最接近8的倍数）。

**内存对齐的原因**

1. **硬件要求**：一些硬件架构要求数据在特定的边界上对齐，以便于访问。如果数据未对齐，CPU可能需要多次内存访问来读取数据，影响性能。
2. **性能优化**：对齐数据可以提高内存访问的速度，因为大多数现代处理器在访问对齐数据时效率更高。



**改变对齐方式**

在C++中，可以使用编译器特定的指令来改变默认的对齐方式。

**`#pragma pack`**

通过 `#pragma pack` 指令，可以指定结构体的对齐方式：

```
cpp复制代码#pragma pack(push, 1)
struct PackedExample {
    char a;
    int b;
    char c;
};
#pragma pack(pop)
```

在这个例子中，`PackedExample`结构体中的成员将不进行对齐和填充，总大小将是 `1 + 4 + 1 = 6` 字节。

**`alignas`**

C++11引入了`alignas`关键字，可以用于显式指定对齐要求：

```cpp
struct AlignasExample {
    char a;
    alignas(8) int b;  // 强制b在8字节边界对齐
    char c;
};
```



**实际内存布局和大小**

可以使用`sizeof`和`offsetof`宏来检查实际内存布局和大小：

```
cpp复制代码#include <iostream>
#include <cstddef>

struct Example {
    char a;
    int b;
    char c;
};

int main() {
    std::cout << "Size of Example: " << sizeof(Example) << std::endl;
    std::cout << "Offset of a: " << offsetof(Example, a) << std::endl;
    std::cout << "Offset of b: " << offsetof(Example, b) << std::endl;
    std::cout << "Offset of c: " << offsetof(Example, c) << std::endl;
    return 0;
}
```

输出可能是：

```
yaml复制代码Size of Example: 12
Offset of a: 0
Offset of b: 4
Offset of c: 8
```



**小结**

- **内存对齐**：指将结构体的成员变量存储在内存中的特定位置，以满足硬件和性能要求。
- **对齐要求**：每个数据类型都有其对齐要求，编译器可能在结构体成员之间插入填充字节。
- **性能优化**：对齐数据可以提高内存访问的速度。
- **改变对齐方式**：可以使用 `#pragma pack` 或 `alignas` 关键字来显式指定对齐方式。
- **检查布局**：使用 `sizeof` 和 `offsetof` 宏来检查实际内存布局和大小。

通过理解和正确使用内存对齐，可以提高程序的性能和兼容性。



# 操作系统

## 堆和栈的区别

![image-20240603205212352](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240603205212352.png)

## 虚拟内存空间分布

![image-20240602195049658](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602195049658.png)

## 线程安全

### 线程安全的数据结构

大部分数据结构都不是线程安全的。线程安全是指在多线程环境下，对数据结构的操作不会导致不确定的行为或数据损坏。如果一个数据结构是线程安全的，那么在多个线程同时对其进行读取和写入操作时，不需要额外的同步手段，就可以保证数据的一致性和正确性。

然而，许多常见的数据结构，如数组、链表、栈、队列等，并没有内置的线程安全保护机制。这意味着在多线程环境下，对这些数据结构的并发访问可能会导致数据竞争、内存泄漏、段错误等问题，从而导致程序的崩溃或不确定的行为。

为了在多线程环境下安全地使用数据结构，可以采取以下几种方法：

1. **互斥锁（Mutex）**：在访问数据结构之前获取互斥锁，在操作完成后释放锁。这样可以保证同一时刻只有一个线程能够访问数据结构，从而避免竞争条件。
2. **原子操作（Atomic Operations）**：使用原子操作来确保特定操作的原子性，从而避免竞争条件。例如，使用原子整数类型来实现计数器或标志位。
3. **线程安全的数据结构**：某些编程语言或库提供了线程安全的数据结构，这些数据结构在内部实现了同步机制，因此可以安全地在多线程环境中使用。
4. **读写锁（Read-Write Lock）**：对于读多写少的情况，可以使用读写锁来提高并发性能。读写锁允许多个线程同时读取数据，但只允许一个线程写入数据。

综上所述，大多数常见的数据结构都不是线程安全的，但可以通过加锁、原子操作、使用线程安全的数据结构或其他同步手段来确保在多线程环境中的安全使用。

**在C++中，有一些线程安全的数据结构可供选择。这些线程安全的数据结构通常包含在C++标准库之外，需要通过第三方库或自定义实现来获取。**

## 进程和线程的区别

![image-20240602170059663](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602170059663.png)



进程切换需要切换内核上下文，从用户态到核心态，线程不需要

## 进程间通信的方法

进程间通信（Inter-Process Communication，IPC）是指在操作系统中，不同进程之间交换数据或信息的机制。不同操作系统提供的IPC机制有所不同，但主要的IPC方法包括以下几种：

### 1. 管道（Pipes）

#### 匿名管道（Anonymous Pipes）

匿名管道是一种半双工的通信机制，数据只能在一个方向上流动。通常用于具有亲缘关系的进程之间的通信，如父进程和子进程。

- **特点**：
  - 简单高效。
  - 只能用于父子进程间的通信。
  - 数据传输方向固定（单向）。
- **使用示例**：
  - `pipe()`系统调用创建匿名管道。
  - `fork()`系统调用创建子进程。
  - 父子进程通过`read()`和`write()`进行通信。

#### 命名管道（Named Pipes, FIFO）

命名管道是一种全双工的通信机制，允许无亲缘关系的进程之间进行通信。

- **特点**：
  - 可以用于无亲缘关系进程间的通信。
  - 支持全双工（双向通信）。
  - 在文件系统中以特殊文件形式存在。
- **使用示例**：
  - `mkfifo()`系统调用创建命名管道。
  - 进程通过普通文件操作接口`open()`、`read()`、`write()`进行通信。

### 2. 消息队列（Message Queues）

消息队列是一种将消息放入队列的机制，不同进程通过消息队列进行通信。消息队列可以实现消息的异步传递。

- **特点**：
  - 支持异步通信。
  - 允许消息优先级排序。
  - 支持多种消息类型。
- **使用示例**：
  - `msgget()`创建或获取一个消息队列。
  - `msgsnd()`向队列发送消息。
  - `msgrcv()`从队列接收消息。

### 3. 共享内存（Shared Memory）

共享内存是一种最快的IPC机制，不同进程通过共享一段内存区域进行通信。

- **特点**：
  - 高效，直接通过内存进行数据交换。
  - 需要同步机制（如信号量）来解决并发访问问题。
  - 支持大数据量传输。
- **使用示例**：
  - `shmget()`创建共享内存段。
  - `shmat()`将共享内存段附加到进程地址空间。
  - `shmdt()`分离共享内存段。

### 4. 信号量（Semaphores）

信号量是一种用于**进程间同步**的机制，通过信号量可以控制多个进程对共享资源的访问。

- **特点**：
  - 用于同步，防止竞争条件。
  - 支持原子操作。
- **使用示例**：
  - `semget()`创建或获取信号量集。
  - `semop()`执行信号量操作（P操作和V操作）。
  - `semctl()`控制信号量集。

### 5. 信号（Signals）

信号是一种用于通知进程某个事件发生的机制。信号可以异步发送给目标进程。

- **特点**：
  - 用于通知和中断。
  - 异步处理。
  - 可能会丢失信号（如果在处理信号期间再次收到同一信号）。
- **使用示例**：
  - `kill()`向进程发送信号。
  - `signal()`或`sigaction()`设置信号处理函数。

### 6. 套接字（Sockets）

套接字是用于网络通信的IPC机制，也可以用于本地进程间的通信（Unix域套接字）。

- **特点**：
  - 支持本地和远程通信。
  - 支持多种协议（TCP、UDP）。
  - 灵活强大。
- **使用示例**：
  - `socket()`创建套接字。
  - `bind()`绑定套接字到地址。
  - `listen()`和`accept()`用于服务端等待连接。
  - `connect()`用于客户端发起连接。
  - `send()`和`recv()`用于数据传输。

### 7. 内存映射文件（Memory-Mapped Files）

内存映射文件是一种将文件内容映射到进程地址空间的机制，多个进程可以通过映射同一个文件实现通信。

- **特点**：
  - 适合大文件的读写。
  - 支持文件和内存的统一操作。
  - 需要同步机制来控制并发访问。
- **使用示例**：
  - `mmap()`创建内存映射。
  - 直接对映射的内存区域进行读写。

### 选择合适的IPC机制

选择哪种IPC机制取决于具体的应用场景和需求：

- 对于简单、短小的数据传输，可以选择管道或消息队列。
- 对于大数据量的传输，可以选择共享内存或内存映射文件。
- 需要同步机制时，可以使用信号量。
- 对于网络通信，可以使用套接字。
- 需要异步通知时，可以使用信号。

每种IPC机制都有其优缺点和适用场景，理解它们的特性可以帮助在实际开发中做出最佳选择。

## 协程

### 什么是协程

协程， 我们又称为微线程，协程它不像进程、线程那样，需要进行系统内核上的上下文切换，**协程的上下文切换是由开发人员决定的**。

协程是一种用户级的轻量级线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态

**协程本质上就是用户态下的线程，所以也有人说协程是 “轻线程”**

进程、线程都涉及内核态切换，调度由操作系统决定



### 为什么要用携程

目前主流语言基本上都选择了多线程作为并发设施，与线程相关的概念就是抢占式多任务（Preemptive multitasking），而与协程相关的是协作式多任务。

其实不管是进程还是线程，每次阻塞、切换都需要陷入系统调用(system call)，先让CPU跑操作系统的调度程序，然后再由调度程序决定该跑哪一个进程(线程)。
而且由于抢占式调度执行顺序无法确定的特点，使用线程时需要非常小心地处理同步问题，而协程完全不存在这个问题（事件驱动和异步程序也有同样的优点）。

**因为协程是用户自己来编写调度逻辑的**，对于我们的CPU来说，协程其实是单线程，所以CPU不用去考虑怎么调度、切换上下文，这就省去了CPU的切换开销，所以协程在一定程度上又好于多线程。

### 协程相对于多线程的优点

多线程编程是比较困难的， 因为调度程序任何时候都能中断线程， 必须记住保留锁， 去保护程序中重要部分， 防止多线程在执行的过程中断。

而协程默认会做好全方位保护， 以防止中断。我们必须显示产出才能让程序的余下部分运行。对协程来说， 无需保留锁， 而在多个线程之间同步操作， 协程自身就会同步， 因为在任意时刻， 只有一个协程运行。总结下大概下面几点：

无需系统内核的上下文切换，减小开销；
无需原子操作锁定及同步的开销，不用担心资源共享的问题；
单线程即可实现高并发，单核 CPU 即便支持上万的协程都不是问题，所以很适合用于高并发处理，尤其是在应用在网络爬虫中。

## 用户态和核心态

用户态（User Mode）和核心态（Kernel Mode）是计算机操作系统中两种不同的操作模式。它们主要用于保护系统资源和数据安全，防止普通应用程序对操作系统的核心部分进行非法访问或操作。下面详细介绍这两种态的区别和作用。

### 用户态（User Mode）

用户态是普通应用程序运行的模式。在用户态下，程序运行的权限受限，不能直接访问硬件资源或操作系统的核心数据结构。用户态程序只能通过系统调用（System Call）请求操作系统提供的服务。

**特点：**

1. **受限权限**：用户态程序不能直接访问硬件资源或关键系统数据。
2. **系统调用**：用户态程序需要通过系统调用接口与操作系统交互，以请求系统资源或服务。
3. **安全性**：这种限制防止了用户程序对系统资源的不当操作，提高了系统的稳定性和安全性。

**示例：**

- 应用程序（如文字处理软件、浏览器等）在用户态下运行，它们通过系统调用请求操作系统执行文件操作、网络通信等任务。

### 核心态（Kernel Mode）

核心态是操作系统内核运行的模式。在核心态下，操作系统拥有最高权限，可以访问所有硬件资源和系统数据结构。核心态通常只对操作系统内核和一些关键系统服务开放。

**特点：**

1. **完全权限**：核心态具有完全的访问权限，可以直接操作硬件和系统数据。
2. **关键任务**：操作系统内核和一些重要的系统服务在核心态下运行，负责管理系统资源、调度任务和处理硬件中断。
3. **高风险**：由于核心态具有完全的访问权限，任何错误或恶意行为都可能导致系统崩溃或安全问题。

**示例：**

- 操作系统内核、设备驱动程序和部分系统服务在核心态下运行。

### 用户态与核心态的切换

当用户态程序需要执行需要高权限的操作（如文件读写、网络通信）时，会通过系统调用进入核心态。这一过程中，CPU会从用户态切换到核心态，执行操作系统内核代码。操作完成后，系统会返回用户态继续执行用户程序。

**切换过程：**

1. 用户程序发出系统调用请求。
2. 系统调用触发陷阱（Trap）指令，CPU切换到核心态。
3. 操作系统内核处理系统调用请求。
4. 操作完成后，CPU切换回用户态，继续执行用户程序。

### 作用与重要性

- **安全性**：通过区分用户态和核心态，可以防止用户程序对系统核心的非法访问和操作，提高系统的安全性。
- **稳定性**：即使用户程序出现错误，也不会直接影响操作系统内核，保证了系统的整体稳定性。
- **资源管理**：操作系统在核心态下统一管理系统资源，实现资源的有效分配和调度。

## 系统调用的流程

![image-20240602170151204](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602170151204.png)

## 中断的上下部

在计算机系统中，中断是指硬件或软件事件打断当前正在执行的任务，转而执行特定的中断处理程序的过程。中断处理程序通常分为上下两个部分：上半部（Top Half）和下半部（Bottom Half）。这种设计有助于提高系统的响应速度和处理效率。以下是对中断上下半部的详细介绍。

### 上半部（Top Half）

上半部是中断处理的第一阶段，通常是在中断发生时立即执行的代码。它的主要任务是快速响应中断，完成一些必须立即处理的工作。

**特点：**

1. **快速执行**：上半部需要尽可能快地执行，以减少中断关闭时间，防止影响系统的整体性能。
2. **关闭中断**：在上半部执行期间，通常会关闭其他中断，以确保处理过程不被打断。
3. **任务分配**：上半部会处理一些紧急的工作，并将复杂或耗时的任务推迟到下半部处理。

**示例：**

- 读取硬件寄存器中的中断信息。
- 清除中断标志，重新使能中断。
- 将需要进一步处理的数据放入队列或缓冲区。

### 下半部（Bottom Half）

下半部是中断处理的第二阶段，它处理上半部推迟的复杂或耗时的任务。下半部通常在上半部完成后、系统允许时执行，以便减少对系统其他部分的影响。

**特点：**

1. **延迟执行**：下半部不是立即执行的，而是在系统资源允许的情况下尽快执行。
2. **允许中断**：下半部执行时，其他中断通常是允许的，以保证系统的响应性。
3. **复杂任务**：下半部适合处理那些不需要立即完成但又相对复杂的任务。

**示例：**

- 处理从设备读取的大量数据。
- 完成网络数据包的处理。
- 更新系统状态或通知其他模块。

### 常见的下半部机制

不同的操作系统有不同的实现下半部的机制，以下是几种常见的方法：

1. **软中断（Softirq）**：软中断是Linux中一种处理下半部的机制，用于处理高频率但低优先级的任务。
2. **任务队列（Tasklets）**：任务队列是Linux中一种基于软中断的机制，允许将工作推迟到稍后执行。
3. **工作队列（Workqueue）**：工作队列是Linux中另一种机制，它允许将任务交给内核线程处理，以实现更加灵活和复杂的任务管理。

### 中断上下半部的工作流程

1. **中断发生**：硬件或软件事件触发中断。
2. **执行上半部**：上半部中断处理程序被立即执行，快速处理紧急任务。
3. **计划下半部**：上半部将需要进一步处理的任务分配给下半部。
4. **恢复正常执行**：上半部完成后，系统恢复正常任务执行。
5. **执行下半部**：系统在适当的时候执行下半部处理程序，完成剩余的任务。

### 优势与应用

- **快速响应**：上半部能够快速响应中断，确保系统对外部事件的及时反应。
- **提高效率**：将复杂任务推迟到下半部处理，减少中断关闭时间，提高系统整体效率。
- **灵活性**：通过不同的下半部机制，可以灵活管理和调度各种延迟任务，适应不同的应用需求。

总结来说，中断的上下半部设计是为了优化系统的中断处理流程，通过快速处理紧急任务和延迟处理复杂任务，确保系统的高效和稳定运行。这种设计在操作系统和实时系统中广泛应用，极大地提升了系统对外部事件的响应能力和处理效率。

## 死锁的四个条件

死锁（Deadlock）是指两个或多个进程在相互等待对方释放资源的情况下进入的一种无限等待状态。死锁的产生必须满足四个必要条件，即互斥条件、占有且等待条件、不剥夺条件和环路等待条件。这四个条件也被称为死锁产生的四要素。

### 1. 互斥条件（Mutual Exclusion）

资源不能共享，且每次只有一个进程可以使用该资源。

**解释：** 某些资源（如打印机、文件）在一个时刻只能被一个进程占用。如果其他进程需要使用该资源，必须等待当前占用该资源的进程释放它。

**示例：** 打印机在打印文档时，其他进程不能使用该打印机。

### 2. 占有且等待条件（Hold and Wait）

一个进程已经占有了某些资源，同时还在等待其他进程占有的资源。

**解释：** 进程在持有资源的情况下，可以提出新的资源请求，但这些请求的资源可能被其他进程占用，导致进程进入等待状态。

**示例：** 进程A已经占有了资源R1，并且在等待资源R2，而资源R2被进程B占用。

### 3. 不剥夺条件（No Preemption）

资源不能被强行剥夺，只有持有该资源的进程才能主动释放它。

**解释：** 资源一旦分配给某个进程，除非进程主动释放，否则其他进程不能强行夺取这些资源。

**示例：** 进程A占有资源R1，直到进程A完成对R1的使用并释放它之前，其他进程不能获取R1。

### 4. 环路等待条件（Circular Wait）

存在一个进程等待链，其中每个进程都在等待下一个进程所占有的资源，形成一个闭环。

**解释：** 在一组等待进程中，存在一个闭环等待链，即进程P1等待进程P2所占有的资源，进程P2等待进程P3所占有的资源，以此类推，直到某个进程Pn等待进程P1所占有的资源。

**示例：** 进程A等待资源R2，资源R2被进程B占用；进程B等待资源R3，资源R3被进程C占用；进程C等待资源R1，资源R1被进程A占用，从而形成环路。

### 总结

这四个条件是死锁产生的必要条件，只有当这四个条件同时满足时，系统才会发生死锁。因此，避免死锁的策略通常是破坏其中一个或多个条件，例如：

- 通过增加资源的可共享性来破坏互斥条件。
- 采用一次性分配所有资源的方法或规定进程在申请资源前必须释放已经占有的资源，来破坏占有且等待条件。
- 允许系统强行剥夺资源，来破坏不剥夺条件。
- 为资源分配设置严格的顺序，来破坏环路等待条件。

理解和掌握这四个条件，对于设计可靠的并发系统和避免死锁问题具有重要意义。

## 阻塞通信和非阻塞通信

阻塞和非阻塞通信是网络编程中的两种基本模式，它们主要区别在于对I/O操作的处理方式。以下是对这两种模式的详细介绍，包括它们的工作原理、优缺点和应用场景。

### 阻塞通信（Blocking Communication）

#### 工作原理

在阻塞模式下，I/O操作会导致调用线程阻塞，直到操作完成。也就是说，当应用程序发起一个I/O请求（如读写数据、接受连接请求）时，程序会暂停执行，等待I/O操作完成后再继续。

#### 特点

- **简单直观**：编程逻辑较为简单，容易理解和实现。
- **顺序执行**：I/O操作按顺序执行，每个操作必须等待上一个操作完成后才能继续。

#### 优点

1. **编程简便**：阻塞模式的代码编写简单，适合初学者和小型应用程序。
2. **错误处理简单**：由于操作是按顺序执行的，错误处理相对简单。

#### 缺点

1. **资源利用率低**：在等待I/O操作完成期间，线程会被阻塞，导致资源（如CPU）闲置，利用率低。
2. **并发处理能力差**：无法高效处理大量并发请求，容易导致性能瓶颈。

### 非阻塞通信（Non-Blocking Communication）

#### 工作原理

在非阻塞模式下，I/O操作不会导致调用线程阻塞。如果操作无法立即完成，函数会立即返回一个错误（如 `EWOULDBLOCK` 或 `EAGAIN`），并由应用程序决定下一步行动。应用程序可以使用轮询或事件驱动机制来处理未完成的I/O操作。

#### 特点

- **异步执行**：I/O操作是异步的，程序在发起I/O请求后可以继续执行其他任务。
- **需要轮询或事件驱动**：为了处理未完成的I/O操作，需要使用轮询或事件驱动机制。

#### 优点

1. **资源利用率高**：由于线程不会被阻塞，可以更高效地利用资源（如CPU）。
2. **高并发处理能力**：可以同时处理大量并发请求，适合高性能网络服务器和应用程序。

#### 缺点

1. **编程复杂**：编程逻辑较为复杂，需要处理未完成的I/O操作和事件驱动机制。
2. **错误处理复杂**：由于操作是异步的，错误处理和状态管理相对复杂。

## 进程的状态

在操作系统中，进程（process）是程序在执行过程中一个动态的实体。进程的状态反映了进程在其生命周期中的不同阶段。虽然不同的操作系统可能使用不同的术语和机制，但通常一个进程可以有以下几种基本状态：

### 1. 新建（New）

- **描述**：进程正在被创建，但尚未准备好执行。
- **典型操作**：操作系统为进程分配必要的资源（如内存、进程控制块等）。

### 2. 就绪（Ready）

- **描述**：进程已准备好执行，并等待CPU的分配。
- **典型操作**：当进程从新建状态转移到就绪状态，或者从阻塞状态（见下文）转移到就绪状态。

### 3. 运行（Running）

- **描述**：进程正在使用CPU执行指令。
- **典型操作**：调度程序将CPU分配给该进程，进程从就绪状态转移到运行状态。

### 4. 阻塞（Blocked）/ 等待（Waiting）

- **描述**：进程正在等待某个事件（如I/O操作完成、某个信号到达等），无法继续执行。
- **典型操作**：进程等待I/O操作、文件锁等资源时，从运行状态转移到阻塞状态。

### 5. 终止（Terminated）

- **描述**：进程的执行已经结束。
- **典型操作**：进程正常完成任务或因某种错误被强制终止，从运行状态转移到终止状态。操作系统会进行清理工作，释放进程占用的资源。

### 6. 挂起（Suspended）

- **描述**：进程的执行被暂停，并且其状态被保存到外部存储器中。
- **典型操作**：操作系统将某些不活跃的进程从内存中移出，以腾出空间给其他进程。当需要恢复时，进程状态从外存重新加载到内存中。

### 状态转换图

进程状态转换可以用一个状态图来表示，通常包括以下几种转换：

- **从新建到就绪**：进程创建完成，进入就绪队列。
- **从就绪到运行**：调度程序选择该进程并分配CPU。
- **从运行到阻塞**：进程等待某个事件完成（如I/O操作）。
- **从阻塞到就绪**：等待的事件完成，进程重新进入就绪队列。
- **从运行到就绪**：CPU时间片到期，进程被移出CPU进入就绪队列。
- **从运行到终止**：进程完成执行或遇到不可恢复的错误，被终止。
- **从就绪/运行/阻塞到挂起**：进程被暂停，其状态被保存到外存。
- **从挂起到就绪/阻塞**：挂起进程重新加载到内存，并进入就绪或阻塞状态。

### 状态图示例

```
plaintext复制代码  +---------+       +---------+       +---------+
  |  新建   | ----> |  就绪   | ----> |  运行   |
  +---------+       +---------+       +---------+
                      ^ |             ^ |      |
                      | |             | |      v
                      | |             | |  +---------+
                      | v             | +> | 阻塞/等待|
                    +--------+        |    +---------+
                    | 挂起/暂停| <----+       
                    +--------+
```

### 进程状态管理的重要性

1. **资源管理**：通过管理进程状态，操作系统能够高效地分配和回收资源，如CPU时间、内存、I/O设备等。
2. **并发性**：通过状态转换和调度机制，操作系统能够支持多个进程的并发执行，提高系统的吞吐量和响应时间。
3. **稳定性和可靠性**：状态管理能够帮助操作系统检测和处理异常情况，如进程死锁、资源饥饿等，保证系统的稳定性和可靠性。

### 不同操作系统的进程状态

尽管上述状态和转换在大多数操作系统中通用，不同的操作系统可能会引入一些特有的状态或机制。例如：

- **Linux**：除了上述基本状态外，Linux还定义了“可中断的睡眠状态”（TASK_INTERRUPTIBLE）和“不可中断的睡眠状态”（TASK_UNINTERRUPTIBLE）来处理不同类型的等待。
- **Windows**：Windows使用“等待状态”（Wait）和“已完成状态”（Completed）等术语来描述进程状态。

总之，理解和管理进程状态是操作系统设计和实现的核心内容之一，它直接影响系统的性能和稳定性。

## 页面置换算法有哪些

![image-20240602170959175](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602170959175.png)

### 2.先进先出

使用一个队列，每次丢掉队头

![image-20240602171313216](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602171313216.png)

### 4.时钟页面置换算法

算法步骤如下：

1. **使用位检查**：

   - 每当访问一个页面时，将该页面的使用位设置为1，表示该页面最近被访问过。
   - 当需要置换一个页面时，检查当前指针指向的页面的使用位。
   - 如果使用位为0，表示该页面没有被最近访问过，可以选择置换该页面。
   - 如果使用位为1，将该位设置为0，表示给该页面一个“二次机会”，并将指针移动到下一个页面，重复上述步骤直到找到一个使用位为0的页面进行置换。

2. **页面置换**：

   - 找到一个使用位为0的页面后，将该页面置换出内存，并将新的页面加载到该位置。

   - 更新指针和使用位，继续处理下一个页面请求。

内存碎片（Memory Fragmentation）是操作系统在分配和释放内存时可能遇到的问题，会导致内存空间不能有效利用。内存碎片主要分为两种：**外部碎片**和**内部碎片**。

- **外部碎片**：指的是在内存中存在足够的总空闲空间，但这些空闲空间不是连续的，无法分配给需要大块内存的请求。
- **内部碎片**：指的是分配的内存块中有一部分没有被使用，而这些未使用的部分无法被其他内存请求使用。

操作系统使用多种技术来处理和减少内存碎片：

## 内存碎片的处理

### 1. 内存分配算法

#### 1.1 首次适配（First Fit）

首次适配算法在内存中从头到尾扫描，找到第一个大小适合的空闲块进行分配。优点是简单高效，缺点是容易在内存前部产生碎片。

#### 1.2 循环首次适配（Next Fit）

循环首次适配算法是首次适配的一种改进，扫描时从上次分配的位置继续寻找，找到合适的空闲块进行分配。这种方法可以避免集中在内存前部产生碎片。

#### 1.3 最佳适配（Best Fit）

最佳适配算法在内存中找到最小的、且能满足请求的空闲块进行分配。优点是减少了浪费，但容易产生许多小的碎片。

#### 1.4 最差适配（Worst Fit）

最差适配算法在内存中找到最大的空闲块进行分配。这样做的目的是避免产生小碎片，但可能导致内存大块空闲区域被浪费。

### 2. 内存压缩（Memory Compaction）

内存压缩是一种减少外部碎片的技术，通过移动内存中的数据，将所有的空闲块合并成一个大的连续空间。内存压缩会带来较高的开销，通常在系统空闲时或内存紧张时进行。

#### 步骤：

1. 暂停内存分配和释放操作。
2. 将所有已分配的内存块移动到内存的一端，保持它们的顺序。
3. 更新所有相关的指针和引用。
4. 将所有的空闲块合并成一个连续的大块。

### 3. 分区分配（Partition Allocation）

#### 3.1 固定分区分配（Fixed Partition Allocation）

内存被划分为固定大小的分区，每个分区一次只分配给一个进程。缺点是会产生内部碎片，因为分区大小可能不完全匹配进程需要。

#### 3.2 动态分区分配（Dynamic Partition Allocation）

内存被动态地划分为适应进程需求的分区。分区的大小和数量可以根据进程需求进行调整，从而减少内部碎片，但可能导致外部碎片。

### 4. 分页（Paging）

分页是一种将物理内存划分为固定大小的页框（通常为4KB），而将逻辑内存划分为相同大小的页的技术。每个页可以映射到任何一个页框，从而避免了外部碎片问题。页表用于管理页和页框之间的映射关系。尽管分页可以消除外部碎片，但仍可能产生少量内部碎片。

### 5. 分段（Segmentation）

分段技术将内存划分为大小可变的段，每个段代表一个逻辑单元（如代码段、数据段、堆栈段等）。分段可以更好地匹配程序的逻辑结构，减少内部碎片，但可能产生外部碎片。段表用于管理段和物理内存之间的映射关系。

### 6. 分页与分段结合（Segmented Paging）

结合分页和分段技术，可以同时利用两者的优点。内存首先被划分为段，每个段再被划分为固定大小的页。段表和页表共同用于管理内存分配和映射，减少了内部和外部碎片。

### 示例

假设一个操作系统使用分页技术管理内存，每个页和页框大小为 4KB。当程序请求 10KB 内存时，操作系统将分配 3 个页（12KB），并将其映射到任意 3 个空闲的页框。这样，即使物理内存中有碎片，程序仍然能够获得所需的连续逻辑内存。

通过以上技术和算法，操作系统能够有效地管理内存，减少内存碎片，提高系统性能和资源利用率。

# 计算机网络

## TCP与UDP有哪些区别

![image-20240602182347244](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602182347244.png)

![image-20240602183037097](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602183037097.png)

![image-20240602183222508](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602183222508.png)

![image-20240602183541789](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602183541789.png)

### 数据传输方式

tcp基于字节流，udp基于报文  

tcp在运输层有MSS（Maximum Segment Size，最大段大小）=1500-20-20=1460字节，在IP层有 MTU（Maximum Transmission Unit，最大传输单元）=1500字节

MTU 是网络层（IP 层）能传输的最大数据包大小，通常为 1500 字节（以太网标准）。

假设 MTU 为 1500 字节，IP 头部为 20 字节，TCP 头部为 20 字节，则 MSS = MTU - IP 头部 - TCP 头部 = 1500 - 20 - 20 = 1460 字节。

### 传输效率

TCP头20字节，UDP头8字节

## TCP如何保证可靠性

### 重传机制

![image-20240602192418050](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602192418050.png)

sack:select ack,在TCP头有一个字段可以用来记录需要重传的数据包

![image-20240602193154212](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20240602193154212.png)

### 滑动窗口

发送方窗口大小由接收方的缓冲区大小和处理能力决定

在TCP头部有字段标记窗口大小

### 流量控制

### 拥塞控制

围绕拥塞窗口cwnd大小,ssthresh大小

慢开始

拥塞避免

快重传：指收到三个重复的ACK后，不必等待重传计时器超时，而是直接重传

快恢复（3-ACK）

## 三次握手和四次挥手

### 三次握手（TCP 建立连接）

1. 客户端发送 SYN
   - 客户端向服务端发送一个 SYN（同步序列编号）包，表示请求建立连接。
2. 服务端发送 SYN + ACK
   - 服务端收到 SYN 包后，如果同意建立连接，会向客户端发送一个 SYN + ACK 包，表示确认收到请求，并同意建立连接。
3. 客户端发送 ACK
   - 客户端收到 SYN + ACK 包后，会向服务端发送一个 ACK 包，表示确认收到确认，并完成连接的建立。

### 四次挥手（TCP 释放连接）

1. 客户端发送 FIN
   - 客户端向服务端发送一个 FIN（结束）包，表示请求关闭连接。
2. 服务端发送 ACK
   - 服务端收到 FIN 包后，会向客户端发送一个 ACK 包，表示确认收到请求，但仍允许数据传输。
3. 服务端发送 FIN
   - 服务端在准备好关闭连接时，会向客户端发送一个 FIN 包，表示自己也准备好关闭连接。
4. 客户端发送 ACK
   - 客户端收到 FIN 包后，会向服务端发送一个 ACK 包，表示确认收到请求，然后连接关闭。

### TIME_WAIT状态

第四次挥手 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态，但此时TCP连接还未终止，必须要经过2MSL后（最长报文寿命），当客户端撤销相应的TCB后，客户端才会进入CLOSED关闭状态，服务器端接收到确认报文后，会立即进入CLOSED关闭状态，到这里TCP连接就断开了，四次挥手完成

为什么客户端要等待2MSL？
主要原因是为了保证客户端发送的第一个ACK报文能到到服务器，因为这个ACK报文可能丢失，并且2MSL是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃，这样新的连接中不会出现旧连接的请求报文。

`TIME_WAIT` 状态是 TCP 连接关闭过程中的一种状态，它发生在 TCP 建立连接的四次挥手过程中。具体来说，在连接的关闭过程中，当一方发送了最后的 ACK 包后，它会进入 `TIME_WAIT` 状态，等待一段时间，以确保对端收到了 ACK 包并且有足够的时间重新发送 FIN 包（如果需要）。

#### `TIME_WAIT` 状态的作用：

1. **确保连接的可靠关闭**：在 `TIME_WAIT` 状态下，等待一段时间可以确保对端收到了自己发送的 ACK 包，以及对端是否有需要重新发送 FIN 包。这样可以保证连接的可靠关闭，避免了可能的数据包重传和连接复用引起的问题。
2. **避免冲突**：在 `TIME_WAIT` 状态下，保留了关闭连接的信息，防止新建立的连接与之前的连接发生冲突。如果不等待一段时间，而是立即关闭连接并释放资源，可能会导致旧连接的数据包在网络中仍然存在，与新连接的数据包发生混淆，造成数据混乱或错误。

## Socket

Socket是一种用于计算机网络通信的编程接口，通过它可以实现两台设备之间的数据交换。Socket广泛应用于网络应用程序的开发，例如网页服务器、客户端程序、即时通讯软件等。下面是对Socket的一些详细介绍：

### 1. Socket的基本概念

Socket在网络通信中扮演了非常重要的角色，是实现网络数据传输的核心。在计算机网络中，Socket通常指的是一个网络通信的端点，它可以在同一台计算机的不同进程之间，或不同计算机的进程之间进行数据交换。

### 2. Socket的类型

Socket主要有以下几种类型：

- **流式套接字（Stream Socket）**：也称为TCP套接字，基于传输控制协议（TCP），提供可靠的、面向连接的通信服务。
- **数据报套接字（Datagram Socket）**：也称为UDP套接字，基于用户数据报协议（UDP），提供不可靠的、无连接的通信服务。

### 3. Socket的工作流程

Socket的基本工作流程通常包括以下几个步骤：

#### 对于服务器端：

1. **创建Socket**：调用`socket()`函数创建一个Socket。
2. **绑定地址（Bind）**：使用`bind()`函数将Socket与特定的IP地址和端口绑定。
3. **监听（Listen）**：使用`listen()`函数将Socket设置为监听状态，等待客户端连接。
4. **接受连接（Accept）**：使用`accept()`函数接受客户端的连接请求，并返回一个新的Socket用于与客户端通信。
5. **数据传输**：通过新创建的Socket与客户端进行数据传输，使用`send()`和`recv()`函数。
6. **关闭Socket**：通信结束后，使用`close()`函数关闭Socket。

#### 对于客户端：

1. **创建Socket**：调用`socket()`函数创建一个Socket。
2. **连接服务器（Connect）**：使用`connect()`函数向服务器发起连接请求。
3. **数据传输**：连接成功后，通过Socket与服务器进行数据传输，使用`send()`和`recv()`函数。
4. **关闭Socket**：通信结束后，使用`close()`函数关闭Socket。

### 4. Socket编程实例

以下是一个简单的Python Socket编程实例：

#### 服务器端代码：

```python
import socket

# 创建Socket对象
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

# 获取本地主机名
host = socket.gethostname()
port = 12345

# 绑定端口
server_socket.bind((host, port))

# 设置最大连接数，超过后排队
server_socket.listen(5)

while True:
    # 建立客户端连接
    client_socket, addr = server_socket.accept()
    print("连接地址: %s" % str(addr))
    
    # 发送信息到客户端
    message = '欢迎访问服务器!'
    client_socket.send(message.encode('utf-8'))
    
    # 关闭连接
    client_socket.close()
```

#### 客户端代码：

```python
import socket

# 创建Socket对象
client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

# 获取本地主机名
host = socket.gethostname()
port = 12345

# 连接到服务器
client_socket.connect((host, port))

# 接收来自服务器的消息
message = client_socket.recv(1024)
print(message.decode('utf-8'))

# 关闭连接
client_socket.close()
```

### 5. 常见的Socket编程问题

- **地址已在使用**：当服务器重新启动时，如果之前的Socket未正确关闭，可能会遇到地址已经在使用的错误，可以通过设置Socket选项`SO_REUSEADDR`解决。
- **数据传输问题**：网络通信中，数据包可能会丢失、延迟或乱序，TCP协议可以解决这些问题，而UDP需要应用层自己处理。
- **并发连接处理**：服务器端需要处理多个客户端连接，可以使用多线程、多进程或异步I/O的方法。

Socket编程在网络通信中非常重要，通过了解和掌握Socket，可以开发出功能强大的网络应用程序。

## Https

HTTPS（HyperText Transfer Protocol Secure）是HTTP协议的安全版本，通过在HTTP基础上添加SSL/TLS层来提供加密和数据完整性保护。HTTPS确保了客户端和服务器之间的通信是加密的，防止数据在传输过程中被窃取或篡改。

### HTTPS的工作原理

HTTPS的工作原理主要依赖于SSL/TLS协议，通过一系列加密和认证步骤来保证数据传输的安全性。

#### 1. SSL/TLS协议概述

SSL（Secure Sockets Layer）和其后继者TLS（Transport Layer Security）是用于在两个通信应用程序之间提供安全连接的协议。HTTPS通常使用TLS协议（尽管习惯上仍称为HTTPS）。

#### 2. HTTPS握手过程

HTTPS连接的建立包括以下主要步骤：

1. **客户端发起连接**：客户端（如浏览器）发起连接请求，并发送一个“ClientHello”消息。此消息包含支持的加密算法列表、客户端生成的随机数以及其他必要信息。
2. **服务器响应**：服务器收到“ClientHello”消息后，选择一个加密算法，并发送“ServerHello”消息，其中包含服务器选择的加密算法、服务器生成的随机数以及服务器的数字证书。
3. **服务器证书验证**：客户端验证服务器的数字证书是否可信（由可信的CA颁发且未过期），并验证证书中的服务器域名是否与客户端请求的域名匹配。
4. **客户端密钥生成**：客户端生成一个预主密钥（pre-master secret），并使用服务器的公钥对其加密，然后发送给服务器。
5. **会话密钥生成**：服务器使用自己的私钥解密预主密钥，客户端和服务器根据预主密钥和之前交换的随机数生成会话密钥（session key）。
6. **完成握手**：双方使用会话密钥加密握手过程的最后几条消息，以确认握手的完成。此时，客户端和服务器之间的所有通信都将使用对称加密进行加密。

### HTTPS的优点

1. **数据加密**：使用对称加密算法对数据进行加密，确保数据在传输过程中不会被窃取。
2. **数据完整性**：通过消息认证码（MAC）或哈希函数来确保数据的完整性，防止数据被篡改。
3. **身份验证**：通过数字证书验证服务器的身份，防止中间人攻击。
4. **隐私保护**：加密的通信渠道防止了网络监听，保护用户隐私。

### HTTPS的缺点

1. **性能开销**：加密和解密过程增加了CPU和内存的使用，对服务器性能有一定影响。
2. **证书管理**：需要从可信的CA获取数字证书，证书的申请、配置和续期都需要管理成本。
3. **兼容性问题**：旧的客户端和服务器可能不支持最新的TLS版本，导致兼容性问题。

### 总结

HTTPS通过在HTTP基础上添加SSL/TLS层来提供加密和数据完整性保护，确保客户端和服务器之间的通信是安全的。HTTPS连接的建立包括一系列复杂的加密和认证步骤，但这些步骤在现代浏览器和服务器中都是自动处理的。尽管HTTPS会带来一定的性能开销和管理成本，但其显著提高的安全性使其成为现代Web应用的标准。

## HTTP

### HTTP/2

#### 主要特点

1. **二进制分帧**：HTTP/2 使用二进制格式，而不是 HTTP/1.1 的纯文本格式。这使得解析更高效且更易于实现。
2. **多路复用**：允许多个请求和响应在一个 TCP 连接上同时进行。这样可以减少因为多个请求而引起的延迟。
3. **头部压缩**：通过 HPACK 压缩算法对 HTTP 头部进行压缩，减少了数据传输的开销。
4. **服务器推送**：服务器可以在客户端明确请求之前，主动向客户端推送资源，以减少延迟。
5. **优先级控制**：客户端可以为不同的流设置优先级，从而更好地控制资源的加载顺序。

#### 优势

- **减少延迟**：多路复用和服务器推送技术显著减少了请求-响应的延迟。
- **更高效的数据传输**：二进制分帧和头部压缩提高了传输效率。

### HTTP/3

#### 主要特点

1. **基于 QUIC 协议**：HTTP/3 使用 QUIC 代替了 TCP 作为传输协议。QUIC 是一个基于 UDP 的协议，提供了更快的连接建立时间和更好的拥塞控制。
2. **更快的连接建立**：QUIC 使用 0-RTT 和 1-RTT 的握手方式，大大缩短了连接建立的时间。
3. **多路复用**：与 HTTP/2 类似，HTTP/3 也支持多路复用，但由于基于 QUIC，可以避免 TCP 的队头阻塞问题。
4. **内置加密**：QUIC 内置了 TLS 加密，确保了数据传输的安全性。

#### 优势

- **更低的延迟**：基于 QUIC 的快速连接建立和改进的多路复用技术，使得 HTTP/3 在高延迟和不稳定的网络环境下表现更佳。
- **更好的性能**：避免了 TCP 的一些固有问题（如队头阻塞），提高了整体传输性能。
- **增强的安全性**：QUIC 内置加密，使得数据传输更加安全。

### 对比

| 特点         | HTTP/2                      | HTTP/3                      |
| ------------ | --------------------------- | --------------------------- |
| 传输协议     | TCP                         | QUIC（基于 UDP）            |
| 数据格式     | 二进制                      | 二进制                      |
| 多路复用     | 是                          | 是                          |
| 头部压缩     | 是（HPACK）                 | 是（QPACK）                 |
| 连接建立速度 | 较慢（TCP 握手 + TLS 握手） | 较快（0-RTT 和 1-RTT 握手） |
| 安全性       | 通过 TLS                    | 内置加密（QUIC 内置 TLS）   |
| 队头阻塞问题 | 可能存在（TCP 层面）        | 避免了（QUIC 层面）         |

HTTP/2 已经被广泛使用，很多现代浏览器和服务器都支持。而 HTTP/3 则是最新的发展方向，虽然还在逐步推广，但已经显示出显著的性能优势，尤其在移动网络和高延迟环境下。

# Linux

## inode

在Linux和Unix文件系统中，`inode`（Index Node）是文件系统的重要概念，用于存储文件的元数据。理解`inode`对深入掌握文件系统的结构和管理至关重要。下面详细讲解`inode`的概念、结构、作用和相关操作。

### `inode`的概念

`inode`是文件系统中用来描述文件和目录的一个数据结构，每个文件或目录都有一个唯一的`inode`。`inode`包含文件的元数据，但不包括文件名和实际数据内容。

### `inode`的结构

`inode`中包含了以下元数据：

- **文件类型**：如普通文件、目录、符号链接等。
- **权限**：文件的读、写、执行权限。
- **硬链接计数**：指向该`inode`的文件名数量。
- **文件所有者**：文件所有者的用户ID（UID）。
- **文件所属组**：文件所属组的组ID（GID）。
- **文件大小**：文件的字节数。
- **时间戳**：文件的创建时间、修改时间和访问时间。
- **数据块指针**：指向文件数据所在的物理存储块。

### `inode`的作用

`inode`在文件系统中的主要作用包括：

1. **管理文件元数据**：`inode`存储文件的元数据，便于文件系统管理文件。
2. **文件数据访问**：通过`inode`中的数据块指针，文件系统可以找到文件数据所在的物理存储位置。
3. **支持硬链接**：硬链接共享同一个`inode`，因此可以通过`inode`号实现多个文件名指向同一个文件。

### `inode`与文件名的关系

文件名和`inode`是通过目录项（directory entry）关联的。目录是包含多个目录项的特殊文件，每个目录项包含文件名和对应的`inode`号。文件系统通过目录项找到文件名对应的`inode`，再通过`inode`访问文件元数据和数据块。

### `inode`号

每个`inode`在文件系统中都有一个唯一的编号，即`inode`号。文件系统通过`inode`号来唯一标识和访问文件。

### `inode`的相关操作

在Linux系统中，可以使用以下命令查看`inode`信息：

1. **查看文件的`inode`号**：

```
bash
复制代码
ls -i filename
```

1. **查看文件系统的`inode`使用情况**：

```
bash
复制代码
df -i
```

1. **查看文件详细信息，包括`inode`号**：

```
bash
复制代码
stat filename
```

#### 示例

```
bash复制代码$ echo "Hello, World!" > file1
$ ls -i file1
12345 file1

$ stat file1
  File: file1
  Size: 14             Blocks: 8          IO Block: 4096   regular file
Device: 802h/2050d      Inode: 12345       Links: 1
Access: (0644/-rw-r--r--)  Uid: ( 1000/  user)   Gid: ( 1000/  group)
Access: 2024-06-23 12:00:00.000000000 +0000
Modify: 2024-06-23 12:00:00.000000000 +0000
Change: 2024-06-23 12:00:00.000000000 +0000
 Birth: -
```

### `inode`的限制

1. **数量有限**：文件系统在创建时分配一定数量的`inode`，因此文件系统能容纳的文件和目录总数是有限的。如果`inode`耗尽，即使磁盘空间仍有剩余，也无法创建新文件。
2. **固定大小**：每个`inode`的大小在文件系统创建时固定，不能动态调整。

### 文件系统类型与`inode`

不同文件系统类型（如Ext2、Ext3、Ext4、XFS、Btrfs）对`inode`的实现有所不同，但基本原理相似。现代文件系统在`inode`结构和管理上进行了许多优化，以提高性能和可靠性。

### 总结

`inode`是Linux和Unix文件系统中的核心概念，负责存储文件的元数据和指向数据块的指针。理解`inode`有助于深入了解文件系统的运作机制，包括文件管理、权限控制和数据访问。通过命令行工具，可以查看和管理`inode`，有效地监控和维护文件系统。

## 软链接和硬链接

在Linux和Unix文件系统中，软链接（Symbolic Link，也称为符号链接）和硬链接（Hard Link）是两种不同的文件链接方式。它们在文件系统的实现和使用上有显著差异。下面详细介绍这两种链接。

### 硬链接（Hard Link）

#### 概念

硬链接是将多个文件名指向同一个物理文件。它们共享相同的索引节点（inode），因此硬链接指向的文件实质上是同一个文件。

#### 特点

1. **共享inode**：硬链接与原文件共享相同的inode号码，因此指向同一个数据块。
2. **文件删除**：删除任意一个硬链接，其他硬链接仍然有效，只有当所有硬链接都被删除时，文件的数据才会被释放。
3. **相同内容**：因为它们指向同一个inode，所以内容完全相同，无论通过哪个硬链接修改文件，所有硬链接都能看到修改后的内容。
4. **不能跨文件系统**：硬链接只能在同一个文件系统中创建，不能跨越不同的文件系统。
5. **不能链接目录**：通常情况下，硬链接不能用于目录（超级用户除外，但这不常见，因为容易破坏文件系统结构）。

#### 创建硬链接

使用`ln`命令创建硬链接：

```
bash
复制代码
ln source_file hard_link
```

#### 示例

```
bash复制代码$ echo "Hello, World!" > file1
$ ln file1 file2
$ ls -li
# 12345 -rw-r--r-- 2 user group 14 Jun 23 12:00 file1
# 12345 -rw-r--r-- 2 user group 14 Jun 23 12:00 file2

$ cat file2
# Hello, World!

$ rm file1
$ cat file2
# Hello, World!
```

在这个例子中，删除`file1`后，`file2`依然存在并且内容未变，因为它们指向同一个inode。

### 软链接（Symbolic Link）

#### 概念

软链接是一个指向另一个文件的特殊文件，类似于Windows中的快捷方式。它包含指向目标文件路径的字符串。

#### 特点

1. **独立inode**：软链接有自己独立的inode号码和数据块，数据块中存储的是目标文件的路径。
2. **路径依赖**：软链接依赖于目标文件的路径，如果目标文件被删除或移动，软链接会失效，变成“悬挂”链接（Broken Link）。
3. **可以跨文件系统**：软链接可以跨越不同的文件系统。
4. **可以链接目录**：软链接可以指向文件和目录。

#### 创建软链接

使用`ln -s`命令创建软链接：

```
bash
复制代码
ln -s target_file symlink
```

#### 示例

```
bash复制代码$ echo "Hello, World!" > file1
$ ln -s file1 file2
$ ls -li
# 12345 -rw-r--r-- 1 user group 14 Jun 23 12:00 file1
# 12346 lrwxrwxrwx 1 user group  5 Jun 23 12:00 file2 -> file1

$ cat file2
# Hello, World!

$ rm file1
$ cat file2
# cat: file2: No such file or directory
```

在这个例子中，删除`file1`后，`file2`变成了“悬挂”链接，无法访问原始内容。

### 硬链接与软链接的比较

| 特性           | 硬链接                   | 软链接                           |
| -------------- | ------------------------ | -------------------------------- |
| inode共享      | 是                       | 否                               |
| 数据块共享     | 是                       | 否                               |
| 可以跨文件系统 | 否                       | 是                               |
| 可以链接目录   | 否                       | 是                               |
| 文件删除影响   | 只有删除所有硬链接才影响 | 删除目标文件后软链接变成悬挂链接 |

### 适用场景

- **硬链接**：适用于需要对同一个文件有多个别名，并且希望在不同位置保持一致性，不适合目录和跨文件系统的情况。
- **软链接**：适用于需要创建快捷方式，链接目录，或需要跨文件系统链接的情况。

理解这两种链接的原理和特性，有助于在实际应用中选择合适的方式来管理文件和目录。

# 数据结构和算法

## 红黑树

红黑树（Red-Black Tree）是一种自平衡二叉查找树，其主要特点是能够在插入、删除和查找操作中保持良好的性能。红黑树的每个节点都带有颜色属性（红色或黑色），通过一系列的规则来保证树的平衡性，使其在最坏情况下的时间复杂度仍然为 O(log⁡n)。

### 红黑树的性质

红黑树有以下五条性质：

1. **每个节点是红色或黑色。**
2. **根节点是黑色。**
3. **每个叶节点（NIL节点）是黑色。**
4. **如果一个节点是红色，则它的两个子节点都是黑色（即没有两个红色节点相连）。**
5. **从任一节点到其每个叶节点的所有路径都包含相同数目的黑色节点（即黑色平衡）。**

这些性质确保了红黑树的平衡性，使其能够高效地进行插入、删除和查找操作。

### 插入操作

插入操作包括以下步骤：

1. **按照二叉查找树的规则插入新节点，初始颜色为红色。**

2. 修复红黑树性质

   - 如果插入的节点是根节点，则将其颜色改为黑色。
   - 如果插入节点的父节点是黑色，则红黑树性质没有被破坏，无需进一步操作。
   - 如果插入节点的父节点是红色，则需要进行修复，修复步骤包括：
     - 重新着色
     - 左旋或右旋

具体修复操作根据插入节点、父节点和叔节点的颜色和位置决定。以下是具体步骤：

#### 插入修复示例

假设新插入的节点为 `N`，其父节点为 `P`，叔节点为 `U`，祖父节点为 `G`。

1. **Case 1：叔节点 `U` 是红色**：
   - 将 `P` 和 `U` 变为黑色，`G` 变为红色。
   - 将 `G` 设为新的当前节点 `N`，继续检查。
2. **Case 2：叔节点 `U` 是黑色，且 `N` 是 `P` 的右子节点**：
   - 将 `P` 作为新的当前节点 `N`，对 `P` 进行左旋。
3. **Case 3：叔节点 `U` 是黑色，且 `N` 是 `P` 的左子节点**：
   - 将 `P` 变为黑色，`G` 变为红色。
   - 对 `G` 进行右旋。

### 删除操作

删除操作相对复杂一些，分为两步：

1. **找到要删除的节点 `N`，并将其删除。**

2. 修复红黑树性质

   - 删除节点 `N` 后，可能会破坏红黑树的性质，需要通过重新着色和旋转操作来修复。

删除操作的具体步骤依赖于删除节点 `N` 的子节点情况：

- **Case 1：`N` 有两个子节点**：
  - 找到 `N` 的中序后继节点 `M`（即 `N` 右子树的最左节点）。
  - 将 `M` 的值赋给 `N`，然后删除节点 `M`。
  - 此时将删除操作转为对节点 `M` 的删除。
- **Case 2：`N` 有一个子节点或没有子节点**：
  - 直接删除 `N`，用其子节点替换（如果有子节点）。

删除节点后，可能会破坏红黑树性质，需要修复。具体修复步骤如下：

#### 删除修复示例

假设删除节点后进行修复的节点为 `X`，其兄弟节点为 `S`。

1. **Case 1：`X` 是根节点**：
   - 直接结束修复。
2. **Case 2：`S` 是红色**：
   - 将 `P` 变为红色，`S` 变为黑色。
   - 对 `P` 进行左旋。
   - 更新 `S` 和 `P`。
3. **Case 3：`S` 是黑色，且 `S` 的两个子节点都是黑色**：
   - 将 `S` 变为红色。
   - 将 `P` 设为新的当前节点 `X`，继续修复。
4. **Case 4：`S` 是黑色，且 `S` 的左子节点是红色，右子节点是黑色**：
   - 将 `S` 变为红色，`S` 的左子节点变为黑色。
   - 对 `S` 进行右旋。
   - 更新 `S`。
5. **Case 5：`S` 是黑色，且 `S` 的右子节点是红色**：
   - 将 `S` 的颜色变为 `P` 的颜色。
   - 将 `P` 变为黑色，`S` 的右子节点变为黑色。
   - 对 `P` 进行左旋。

### 红黑树的应用

红黑树广泛应用于需要高效动态集合操作的数据结构中，如：

- **关联容器**：C++ STL 中的 `map`、`set`、`multimap` 和 `multiset` 都使用红黑树实现。
- **Linux 内核**：用于管理虚拟内存区域（VMA）。
- **Java 集合框架**：如 `TreeMap` 和 `TreeSet`。

### 总结

红黑树是一种高效的自平衡二叉查找树，具有良好的最坏情况时间复杂度。通过严格的颜色和结构规则，红黑树能够在插入、删除和查找操作中保持平衡，确保操作的时间复杂度为 O(log⁡n)

## 跳表

跳表 (Skip List) 是由 William Pugh 发明的一种查找数据结构，支持对数据的快速查找，插入和删除。

跳表的期望空间复杂度为O(n) ![O(n)](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)，跳表的查询，插入和删除操作的期望时间复杂度都为 O(logn)

[跳表 - OI Wiki ](https://oi-wiki.org/ds/skiplist/)

## 排序算法特点

不稳定的排序算法：shell,选择排序，快排，堆排

## 链表

### 判断一个链表是否有环

暴力（n^2)

快慢指针，哈希表，Set集合大小变化（n）

# 游戏研发

## 战力排行榜该怎么设计

### 1.数据结构

**A.红黑树**

**B. 跳表**

### 2. 更新策略

玩家的战力变化需要及时更新排行榜，这可以通过以下方式实现：

- **定时更新**：定时批量更新排行榜，适合战力变化频率较低的情况。
- **实时更新**：玩家战力变化时立即更新排行榜，适合战力变化频繁的情况。
- **混合更新**：对频繁变化的玩家进行实时更新，对不频繁变化的玩家进行定时更新。

### 3. 性能优化

为了保证排行榜的高效更新和查询，需要进行以下优化：

- **缓存**：使用缓存机制，将最常用的前N名玩家信息缓存在内存中，减少查询延迟。
- **分片**：对于大规模的排行榜，可以按服务器或地域进行分片，减少单个服务器的负载。
- **批量处理**：对于定时更新，可以批量处理多个玩家的战力变化，减少更新操作的开销。

### 4. 持久化

为了保证数据的持久性，需要将排行榜数据持久化存储到数据库中。常用的数据库有：

- **关系型数据库**（如MySQL、PostgreSQL）：适合结构化数据的存储，支持复杂查询。
- **NoSQL数据库**（如Redis、MongoDB）：适合高并发读写场景，支持快速数据访问。

### 5. 数据库设计

设计数据库表来存储玩家和排行榜信息，例如：

- **Players表**：
  - `id`: 玩家唯一标识
  - `name`: 玩家名字
  - `power`: 玩家战力
- **Leaderboard表**：
  - `rank`: 排名
  - `player_id`: 玩家唯一标识

### 6.处理并发

在高并发环境下，需要处理多个玩家同时更新战力的情况。可以使用数据库的事务和锁机制来保证数据一致性。

### 总结

设计游戏中的战力排行榜涉及数据结构选择、更新策略、性能优化和持久化等多个方面。选择合适的数据结构和更新策略可以保证排行榜的高效和准确，同时结合数据库的持久化和并发控制，确保数据的一致性和可靠性。

# 计算机组成原理

## 冯诺依曼架构

冯·诺依曼架构，也称为普林斯顿架构，是计算机科学中最基础的计算机体系结构之一，由约翰·冯·诺依曼于1945年提出。该架构定义了现代计算机系统的基本组成部分和它们之间的关系。以下是冯·诺依曼架构的主要组成部分和特点：

### 组成部分

1. **中央处理器（CPU）**：
   - **算术逻辑单元（ALU）**：负责执行算术和逻辑运算。
   - **控制单元（CU）**：负责解释指令并控制其他组件的操作。
   - **寄存器**：用于临时存储数据和指令。
2. **存储器（Memory）**：
   - 存储指令和数据的主要存储设备，通常指主存储器（RAM）。
3. **输入设备（Input Devices）**：
   - 用于将数据和指令输入计算机的设备，如键盘和鼠标。
4. **输出设备（Output Devices）**：
   - 用于将计算结果输出到用户的设备，如显示器和打印机。
5. **总线系统（Bus System）**：
   - 数据总线：传输数据。
   - 地址总线：传输地址信息。
   - 控制总线：传输控制信号。

### 主要特点

1. **存储程序概念**：
   - 程序指令和数据存储在同一个存储器中，计算机可以通过读取存储器中的指令来执行程序。
2. **顺序执行**：
   - 指令按顺序执行，一个接一个，除非程序中有跳转指令（如条件分支或循环）。
3. **单一存储器**：
   - 指令和数据共用同一存储器，通过地址总线和数据总线访问存储器中的内容。

### 工作原理

冯·诺依曼架构的工作原理可以简化为以下几个步骤：

1. **取指令（Fetch）**：
   - CPU从存储器中取出下一条要执行的指令。程序计数器（PC）存储了下一条指令的地址。
2. **解码（Decode）**：
   - 控制单元（CU）将取出的指令解码，以确定要执行的操作和所需的操作数。
3. **执行（Execute）**：
   - 算术逻辑单元（ALU）执行指令中指定的操作，如加法、减法、逻辑运算等。
4. **存储（Store）**：
   - 将计算结果存储到寄存器或存储器中。



